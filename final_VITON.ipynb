{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_VITON.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchgeometry"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbyY_MKyjfVW",
        "outputId": "611cb0b9-dca9-435a-f823-4d7fd368198c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchgeometry\n",
            "  Downloading torchgeometry-0.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from torchgeometry) (1.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->torchgeometry) (4.1.1)\n",
            "Installing collected packages: torchgeometry\n",
            "Successfully installed torchgeometry-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnu4ji05ercq"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "import os\n",
        "from os import path as osp\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image, ImageDraw\n",
        "import cv2\n",
        "\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn import init\n",
        "from torch.nn.utils.spectral_norm import spectral_norm\n",
        "from torch.utils import data\n",
        "from torchvision import transforms\n",
        "import torchgeometry as tgm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BaseNetwork, self).__init__()\n",
        "\n",
        "    def print_network(self):\n",
        "        num_params = 0\n",
        "        for param in self.parameters():\n",
        "            num_params += param.numel()\n",
        "        print(\"Network [{}] was created. Total number of parameters: {:.1f} million. \"\n",
        "              \"To see the architecture, do print(network).\".format(self.__class__.__name__, num_params / 1000000))\n",
        "\n",
        "    def init_weights(self, init_type='normal', gain=0.02):\n",
        "        def init_func(m):\n",
        "            classname = m.__class__.__name__\n",
        "            if 'BatchNorm2d' in classname:\n",
        "                if hasattr(m, 'weight') and m.weight is not None:\n",
        "                    init.normal_(m.weight.data, 1.0, gain)\n",
        "                if hasattr(m, 'bias') and m.bias is not None:\n",
        "                    init.constant_(m.bias.data, 0.0)\n",
        "            elif ('Conv' in classname or 'Linear' in classname) and hasattr(m, 'weight'):\n",
        "                if init_type == 'normal':\n",
        "                    init.normal_(m.weight.data, 0.0, gain)\n",
        "                elif init_type == 'xavier':\n",
        "                    init.xavier_normal_(m.weight.data, gain=gain)\n",
        "                elif init_type == 'xavier_uniform':\n",
        "                    init.xavier_uniform_(m.weight.data, gain=1.0)\n",
        "                elif init_type == 'kaiming':\n",
        "                    init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "                elif init_type == 'orthogonal':\n",
        "                    init.orthogonal_(m.weight.data, gain=gain)\n",
        "                elif init_type == 'none':  # uses pytorch's default init method\n",
        "                    m.reset_parameters()\n",
        "                else:\n",
        "                    raise NotImplementedError(\"initialization method '{}' is not implemented\".format(init_type))\n",
        "                if hasattr(m, 'bias') and m.bias is not None:\n",
        "                    init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "        self.apply(init_func)\n",
        "\n",
        "    def forward(self, *inputs):\n",
        "        pass"
      ],
      "metadata": {
        "id": "S2Y_9DGee9ZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegGenerator(BaseNetwork):\n",
        "    def __init__(self, opt, input_nc, output_nc=13, norm_layer=nn.InstanceNorm2d):\n",
        "        super(SegGenerator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(input_nc, 64, kernel_size=3, padding=1), norm_layer(64), nn.ReLU(),\n",
        "                                   nn.Conv2d(64, 64, kernel_size=3, padding=1), norm_layer(64), nn.ReLU())\n",
        "\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=3, padding=1), norm_layer(128), nn.ReLU(),\n",
        "                                   nn.Conv2d(128, 128, kernel_size=3, padding=1), norm_layer(128), nn.ReLU())\n",
        "\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(128, 256, kernel_size=3, padding=1), norm_layer(256), nn.ReLU(),\n",
        "                                   nn.Conv2d(256, 256, kernel_size=3, padding=1), norm_layer(256), nn.ReLU())\n",
        "\n",
        "        self.conv4 = nn.Sequential(nn.Conv2d(256, 512, kernel_size=3, padding=1), norm_layer(512), nn.ReLU(),\n",
        "                                   nn.Conv2d(512, 512, kernel_size=3, padding=1), norm_layer(512), nn.ReLU())\n",
        "\n",
        "        self.conv5 = nn.Sequential(nn.Conv2d(512, 1024, kernel_size=3, padding=1), norm_layer(1024), nn.ReLU(),\n",
        "                                   nn.Conv2d(1024, 1024, kernel_size=3, padding=1), norm_layer(1024), nn.ReLU())\n",
        "\n",
        "        self.up6 = nn.Sequential(nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "                                 nn.Conv2d(1024, 512, kernel_size=3, padding=1), norm_layer(512), nn.ReLU())\n",
        "        self.conv6 = nn.Sequential(nn.Conv2d(1024, 512, kernel_size=3, padding=1), norm_layer(512), nn.ReLU(),\n",
        "                                   nn.Conv2d(512, 512, kernel_size=3, padding=1), norm_layer(512), nn.ReLU())\n",
        "\n",
        "        self.up7 = nn.Sequential(nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "                                 nn.Conv2d(512, 256, kernel_size=3, padding=1), norm_layer(256), nn.ReLU())\n",
        "        self.conv7 = nn.Sequential(nn.Conv2d(512, 256, kernel_size=3, padding=1), norm_layer(256), nn.ReLU(),\n",
        "                                   nn.Conv2d(256, 256, kernel_size=3, padding=1), norm_layer(256), nn.ReLU())\n",
        "\n",
        "        self.up8 = nn.Sequential(nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "                                 nn.Conv2d(256, 128, kernel_size=3, padding=1), norm_layer(128), nn.ReLU())\n",
        "        self.conv8 = nn.Sequential(nn.Conv2d(256, 128, kernel_size=3, padding=1), norm_layer(128), nn.ReLU(),\n",
        "                                   nn.Conv2d(128, 128, kernel_size=3, padding=1), norm_layer(128), nn.ReLU())\n",
        "\n",
        "        self.up9 = nn.Sequential(nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "                                 nn.Conv2d(128, 64, kernel_size=3, padding=1), norm_layer(64), nn.ReLU())\n",
        "        self.conv9 = nn.Sequential(nn.Conv2d(128, 64, kernel_size=3, padding=1), norm_layer(64), nn.ReLU(),\n",
        "                                   nn.Conv2d(64, 64, kernel_size=3, padding=1), norm_layer(64), nn.ReLU(),\n",
        "                                   nn.Conv2d(64, output_nc, kernel_size=3, padding=1))\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.drop = nn.Dropout(0.5)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        self.print_network()\n",
        "        self.init_weights(opt.init_type, opt.init_variance)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.conv1(x)\n",
        "        conv2 = self.conv2(self.pool(conv1))\n",
        "        conv3 = self.conv3(self.pool(conv2))\n",
        "        conv4 = self.drop(self.conv4(self.pool(conv3)))\n",
        "        conv5 = self.drop(self.conv5(self.pool(conv4)))\n",
        "\n",
        "        conv6 = self.conv6(torch.cat((conv4, self.up6(conv5)), 1))\n",
        "        conv7 = self.conv7(torch.cat((conv3, self.up7(conv6)), 1))\n",
        "        conv8 = self.conv8(torch.cat((conv2, self.up8(conv7)), 1))\n",
        "        conv9 = self.conv9(torch.cat((conv1, self.up9(conv8)), 1))\n",
        "        return self.sigmoid(conv9)"
      ],
      "metadata": {
        "id": "jvR5bsO6fGKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtraction(BaseNetwork):\n",
        "    def __init__(self, input_nc, ngf=64, num_layers=4, norm_layer=nn.BatchNorm2d):\n",
        "        super(FeatureExtraction, self).__init__()\n",
        "\n",
        "        nf = ngf\n",
        "        layers = [nn.Conv2d(input_nc, nf, kernel_size=4, stride=2, padding=1), nn.ReLU(), norm_layer(nf)]\n",
        "\n",
        "        for i in range(1, num_layers):\n",
        "            nf_prev = nf\n",
        "            nf = min(nf * 2, 512)\n",
        "            layers += [nn.Conv2d(nf_prev, nf, kernel_size=4, stride=2, padding=1), nn.ReLU(), norm_layer(nf)]\n",
        "\n",
        "        layers += [nn.Conv2d(nf, 512, kernel_size=3, stride=1, padding=1), nn.ReLU(), norm_layer(512)]\n",
        "        layers += [nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1), nn.ReLU()]\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "Jg3cce1TfJt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureCorrelation(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeatureCorrelation, self).__init__()\n",
        "\n",
        "    def forward(self, featureA, featureB):\n",
        "        # Reshape features for matrix multiplication.\n",
        "        b, c, h, w = featureA.size()\n",
        "        featureA = featureA.permute(0, 3, 2, 1).reshape(b, w * h, c)\n",
        "        featureB = featureB.reshape(b, c, h * w)\n",
        "\n",
        "        # Perform matrix multiplication.\n",
        "        corr = torch.bmm(featureA, featureB).reshape(b, w * h, h, w)\n",
        "        return corr"
      ],
      "metadata": {
        "id": "h2ivsBWGfNNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureRegression(nn.Module):\n",
        "    def __init__(self, input_nc=512, output_size=6, norm_layer=nn.BatchNorm2d):\n",
        "        super(FeatureRegression, self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(input_nc, 512, kernel_size=4, stride=2, padding=1), norm_layer(512), nn.ReLU(),\n",
        "            nn.Conv2d(512, 256, kernel_size=4, stride=2, padding=1), norm_layer(256), nn.ReLU(),\n",
        "            nn.Conv2d(256, 128, kernel_size=3, padding=1), norm_layer(128), nn.ReLU(),\n",
        "            nn.Conv2d(128, 64, kernel_size=3, padding=1), norm_layer(64), nn.ReLU()\n",
        "        )\n",
        "        self.linear = nn.Linear(64 * (input_nc // 16), output_size)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.linear(x.reshape(x.size(0), -1))\n",
        "        return self.tanh(x)"
      ],
      "metadata": {
        "id": "GVHiyxvcfTcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TpsGridGen(nn.Module):\n",
        "    def __init__(self, opt, dtype=torch.float):\n",
        "        super(TpsGridGen, self).__init__()\n",
        "\n",
        "        # Create a grid in numpy.\n",
        "        # TODO: set an appropriate interval ([-1, 1] in CP-VTON, [-0.9, 0.9] in the current version of VITON-HD)\n",
        "        grid_X, grid_Y = np.meshgrid(np.linspace(-0.9, 0.9, opt.load_width), np.linspace(-0.9, 0.9, opt.load_height))\n",
        "        grid_X = torch.tensor(grid_X, dtype=dtype).unsqueeze(0).unsqueeze(3)  # size: (1, h, w, 1)\n",
        "        grid_Y = torch.tensor(grid_Y, dtype=dtype).unsqueeze(0).unsqueeze(3)  # size: (1, h, w, 1)\n",
        "\n",
        "        # Initialize the regular grid for control points P.\n",
        "        self.N = opt.grid_size * opt.grid_size\n",
        "        coords = np.linspace(-0.9, 0.9, opt.grid_size)\n",
        "        # FIXME: why P_Y and P_X are swapped?\n",
        "        P_Y, P_X = np.meshgrid(coords, coords)\n",
        "        P_X = torch.tensor(P_X, dtype=dtype).reshape(self.N, 1)\n",
        "        P_Y = torch.tensor(P_Y, dtype=dtype).reshape(self.N, 1)\n",
        "        P_X_base = P_X.clone()\n",
        "        P_Y_base = P_Y.clone()\n",
        "\n",
        "        Li = self.compute_L_inverse(P_X, P_Y).unsqueeze(0)\n",
        "        P_X = P_X.unsqueeze(2).unsqueeze(3).unsqueeze(4).transpose(0, 4)  # size: (1, 1, 1, 1, self.N)\n",
        "        P_Y = P_Y.unsqueeze(2).unsqueeze(3).unsqueeze(4).transpose(0, 4)  # size: (1, 1, 1, 1, self.N)\n",
        "\n",
        "        self.register_buffer('grid_X', grid_X, False)\n",
        "        self.register_buffer('grid_Y', grid_Y, False)\n",
        "        self.register_buffer('P_X_base', P_X_base, False)\n",
        "        self.register_buffer('P_Y_base', P_Y_base, False)\n",
        "        self.register_buffer('Li', Li, False)\n",
        "        self.register_buffer('P_X', P_X, False)\n",
        "        self.register_buffer('P_Y', P_Y, False)\n",
        "\n",
        "    # TODO: refactor\n",
        "    def compute_L_inverse(self,X,Y):\n",
        "        N = X.size()[0] # num of points (along dim 0)\n",
        "        # construct matrix K\n",
        "        Xmat = X.expand(N,N)\n",
        "        Ymat = Y.expand(N,N)\n",
        "        P_dist_squared = torch.pow(Xmat-Xmat.transpose(0,1),2)+torch.pow(Ymat-Ymat.transpose(0,1),2)\n",
        "        P_dist_squared[P_dist_squared==0]=1 # make diagonal 1 to avoid NaN in log computation\n",
        "        K = torch.mul(P_dist_squared,torch.log(P_dist_squared))\n",
        "        # construct matrix L\n",
        "        O = torch.FloatTensor(N,1).fill_(1)\n",
        "        Z = torch.FloatTensor(3,3).fill_(0)\n",
        "        P = torch.cat((O,X,Y),1)\n",
        "        L = torch.cat((torch.cat((K,P),1),torch.cat((P.transpose(0,1),Z),1)),0)\n",
        "        Li = torch.inverse(L)\n",
        "        return Li\n",
        "\n",
        "    # TODO: refactor\n",
        "    def apply_transformation(self,theta,points):\n",
        "        if theta.dim()==2:\n",
        "            theta = theta.unsqueeze(2).unsqueeze(3)\n",
        "        # points should be in the [B,H,W,2] format,\n",
        "        # where points[:,:,:,0] are the X coords\n",
        "        # and points[:,:,:,1] are the Y coords\n",
        "\n",
        "        # input are the corresponding control points P_i\n",
        "        batch_size = theta.size()[0]\n",
        "        # split theta into point coordinates\n",
        "        Q_X=theta[:,:self.N,:,:].squeeze(3)\n",
        "        Q_Y=theta[:,self.N:,:,:].squeeze(3)\n",
        "        Q_X = Q_X + self.P_X_base.expand_as(Q_X)\n",
        "        Q_Y = Q_Y + self.P_Y_base.expand_as(Q_Y)\n",
        "\n",
        "        # get spatial dimensions of points\n",
        "        points_b = points.size()[0]\n",
        "        points_h = points.size()[1]\n",
        "        points_w = points.size()[2]\n",
        "\n",
        "        # repeat pre-defined control points along spatial dimensions of points to be transformed\n",
        "        P_X = self.P_X.expand((1,points_h,points_w,1,self.N))\n",
        "        P_Y = self.P_Y.expand((1,points_h,points_w,1,self.N))\n",
        "\n",
        "        # compute weigths for non-linear part\n",
        "        W_X = torch.bmm(self.Li[:,:self.N,:self.N].expand((batch_size,self.N,self.N)),Q_X)\n",
        "        W_Y = torch.bmm(self.Li[:,:self.N,:self.N].expand((batch_size,self.N,self.N)),Q_Y)\n",
        "        # reshape\n",
        "        # W_X,W,Y: size [B,H,W,1,N]\n",
        "        W_X = W_X.unsqueeze(3).unsqueeze(4).transpose(1,4).repeat(1,points_h,points_w,1,1)\n",
        "        W_Y = W_Y.unsqueeze(3).unsqueeze(4).transpose(1,4).repeat(1,points_h,points_w,1,1)\n",
        "        # compute weights for affine part\n",
        "        A_X = torch.bmm(self.Li[:,self.N:,:self.N].expand((batch_size,3,self.N)),Q_X)\n",
        "        A_Y = torch.bmm(self.Li[:,self.N:,:self.N].expand((batch_size,3,self.N)),Q_Y)\n",
        "        # reshape\n",
        "        # A_X,A,Y: size [B,H,W,1,3]\n",
        "        A_X = A_X.unsqueeze(3).unsqueeze(4).transpose(1,4).repeat(1,points_h,points_w,1,1)\n",
        "        A_Y = A_Y.unsqueeze(3).unsqueeze(4).transpose(1,4).repeat(1,points_h,points_w,1,1)\n",
        "\n",
        "        # compute distance P_i - (grid_X,grid_Y)\n",
        "        # grid is expanded in point dim 4, but not in batch dim 0, as points P_X,P_Y are fixed for all batch\n",
        "        points_X_for_summation = points[:,:,:,0].unsqueeze(3).unsqueeze(4).expand(points[:,:,:,0].size()+(1,self.N))\n",
        "        points_Y_for_summation = points[:,:,:,1].unsqueeze(3).unsqueeze(4).expand(points[:,:,:,1].size()+(1,self.N))\n",
        "\n",
        "        if points_b==1:\n",
        "            delta_X = points_X_for_summation-P_X\n",
        "            delta_Y = points_Y_for_summation-P_Y\n",
        "        else:\n",
        "            # use expanded P_X,P_Y in batch dimension\n",
        "            delta_X = points_X_for_summation-P_X.expand_as(points_X_for_summation)\n",
        "            delta_Y = points_Y_for_summation-P_Y.expand_as(points_Y_for_summation)\n",
        "\n",
        "        dist_squared = torch.pow(delta_X,2)+torch.pow(delta_Y,2)\n",
        "        # U: size [1,H,W,1,N]\n",
        "        dist_squared[dist_squared==0]=1 # avoid NaN in log computation\n",
        "        U = torch.mul(dist_squared,torch.log(dist_squared))\n",
        "\n",
        "        # expand grid in batch dimension if necessary\n",
        "        points_X_batch = points[:,:,:,0].unsqueeze(3)\n",
        "        points_Y_batch = points[:,:,:,1].unsqueeze(3)\n",
        "        if points_b==1:\n",
        "            points_X_batch = points_X_batch.expand((batch_size,)+points_X_batch.size()[1:])\n",
        "            points_Y_batch = points_Y_batch.expand((batch_size,)+points_Y_batch.size()[1:])\n",
        "\n",
        "        points_X_prime = A_X[:,:,:,:,0]+ \\\n",
        "                       torch.mul(A_X[:,:,:,:,1],points_X_batch) + \\\n",
        "                       torch.mul(A_X[:,:,:,:,2],points_Y_batch) + \\\n",
        "                       torch.sum(torch.mul(W_X,U.expand_as(W_X)),4)\n",
        "\n",
        "        points_Y_prime = A_Y[:,:,:,:,0]+ \\\n",
        "                       torch.mul(A_Y[:,:,:,:,1],points_X_batch) + \\\n",
        "                       torch.mul(A_Y[:,:,:,:,2],points_Y_batch) + \\\n",
        "                       torch.sum(torch.mul(W_Y,U.expand_as(W_Y)),4)\n",
        "\n",
        "        return torch.cat((points_X_prime,points_Y_prime),3)\n",
        "\n",
        "    def forward(self, theta):\n",
        "        warped_grid = self.apply_transformation(theta, torch.cat((self.grid_X, self.grid_Y), 3))\n",
        "        return warped_grid"
      ],
      "metadata": {
        "id": "vg1k7-SNfWor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GMM(nn.Module):\n",
        "    def __init__(self, opt, inputA_nc, inputB_nc):\n",
        "        super(GMM, self).__init__()\n",
        "\n",
        "        self.extractionA = FeatureExtraction(inputA_nc, ngf=64, num_layers=4)\n",
        "        self.extractionB = FeatureExtraction(inputB_nc, ngf=64, num_layers=4)\n",
        "        self.correlation = FeatureCorrelation()\n",
        "        self.regression = FeatureRegression(input_nc=(opt.load_width // 64) * (opt.load_height // 64),\n",
        "                                            output_size=2 * opt.grid_size**2)\n",
        "        self.gridGen = TpsGridGen(opt)\n",
        "\n",
        "    def forward(self, inputA, inputB):\n",
        "        featureA = F.normalize(self.extractionA(inputA), dim=1)\n",
        "        featureB = F.normalize(self.extractionB(inputB), dim=1)\n",
        "        corr = self.correlation(featureA, featureB)\n",
        "        theta = self.regression(corr)\n",
        "\n",
        "        warped_grid = self.gridGen(theta)\n",
        "        return theta, warped_grid"
      ],
      "metadata": {
        "id": "TCxncyJDfd5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskNorm(nn.Module):\n",
        "    def __init__(self, norm_nc):\n",
        "        super(MaskNorm, self).__init__()\n",
        "\n",
        "        self.norm_layer = nn.InstanceNorm2d(norm_nc, affine=False)\n",
        "\n",
        "    def normalize_region(self, region, mask):\n",
        "        b, c, h, w = region.size()\n",
        "\n",
        "        num_pixels = mask.sum((2, 3), keepdim=True)  # size: (b, 1, 1, 1)\n",
        "        num_pixels[num_pixels == 0] = 1\n",
        "        mu = region.sum((2, 3), keepdim=True) / num_pixels  # size: (b, c, 1, 1)\n",
        "\n",
        "        normalized_region = self.norm_layer(region + (1 - mask) * mu)\n",
        "        return normalized_region * torch.sqrt(num_pixels / (h * w))\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        mask = mask.detach()\n",
        "        normalized_foreground = self.normalize_region(x * mask, mask)\n",
        "        normalized_background = self.normalize_region(x * (1 - mask), 1 - mask)\n",
        "        return normalized_foreground + normalized_background\n"
      ],
      "metadata": {
        "id": "mNtWTxVgfh7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ALIASNorm(nn.Module):\n",
        "    def __init__(self, norm_type, norm_nc, label_nc):\n",
        "        super(ALIASNorm, self).__init__()\n",
        "\n",
        "        self.noise_scale = nn.Parameter(torch.zeros(norm_nc))\n",
        "\n",
        "        assert norm_type.startswith('alias')\n",
        "        param_free_norm_type = norm_type[len('alias'):]\n",
        "        if param_free_norm_type == 'batch':\n",
        "            self.param_free_norm = nn.BatchNorm2d(norm_nc, affine=False)\n",
        "        elif param_free_norm_type == 'instance':\n",
        "            self.param_free_norm = nn.InstanceNorm2d(norm_nc, affine=False)\n",
        "        elif param_free_norm_type == 'mask':\n",
        "            self.param_free_norm = MaskNorm(norm_nc)\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"'{}' is not a recognized parameter-free normalization type in ALIASNorm\".format(param_free_norm_type)\n",
        "            )\n",
        "\n",
        "        nhidden = 128\n",
        "        ks = 3\n",
        "        pw = ks // 2\n",
        "        self.conv_shared = nn.Sequential(nn.Conv2d(label_nc, nhidden, kernel_size=ks, padding=pw), nn.ReLU())\n",
        "        self.conv_gamma = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=pw)\n",
        "        self.conv_beta = nn.Conv2d(nhidden, norm_nc, kernel_size=ks, padding=pw)\n",
        "\n",
        "    def forward(self, x, seg, misalign_mask=None):\n",
        "        # Part 1. Generate parameter-free normalized activations.\n",
        "        b, c, h, w = x.size()\n",
        "        noise = (torch.randn(b, w, h, 1).cuda() * self.noise_scale).transpose(1, 3)\n",
        "\n",
        "        if misalign_mask is None:\n",
        "            normalized = self.param_free_norm(x + noise)\n",
        "        else:\n",
        "            normalized = self.param_free_norm(x + noise, misalign_mask)\n",
        "\n",
        "        # Part 2. Produce affine parameters conditioned on the segmentation map.\n",
        "        actv = self.conv_shared(seg)\n",
        "        gamma = self.conv_gamma(actv)\n",
        "        beta = self.conv_beta(actv)\n",
        "\n",
        "        # Apply the affine parameters.\n",
        "        output = normalized * (1 + gamma) + beta\n",
        "        return output"
      ],
      "metadata": {
        "id": "omNP9uF5flZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ALIASResBlock(nn.Module):\n",
        "    def __init__(self, opt, input_nc, output_nc, use_mask_norm=True):\n",
        "        super(ALIASResBlock, self).__init__()\n",
        "\n",
        "        self.learned_shortcut = (input_nc != output_nc)\n",
        "        middle_nc = min(input_nc, output_nc)\n",
        "\n",
        "        self.conv_0 = nn.Conv2d(input_nc, middle_nc, kernel_size=3, padding=1)\n",
        "        self.conv_1 = nn.Conv2d(middle_nc, output_nc, kernel_size=3, padding=1)\n",
        "        if self.learned_shortcut:\n",
        "            self.conv_s = nn.Conv2d(input_nc, output_nc, kernel_size=1, bias=False)\n",
        "\n",
        "        subnorm_type = opt.norm_G\n",
        "        if subnorm_type.startswith('spectral'):\n",
        "            subnorm_type = subnorm_type[len('spectral'):]\n",
        "            self.conv_0 = spectral_norm(self.conv_0)\n",
        "            self.conv_1 = spectral_norm(self.conv_1)\n",
        "            if self.learned_shortcut:\n",
        "                self.conv_s = spectral_norm(self.conv_s)\n",
        "\n",
        "        semantic_nc = opt.semantic_nc\n",
        "        if use_mask_norm:\n",
        "            subnorm_type = 'aliasmask'\n",
        "            semantic_nc = semantic_nc + 1\n",
        "\n",
        "        self.norm_0 = ALIASNorm(subnorm_type, input_nc, semantic_nc)\n",
        "        self.norm_1 = ALIASNorm(subnorm_type, middle_nc, semantic_nc)\n",
        "        if self.learned_shortcut:\n",
        "            self.norm_s = ALIASNorm(subnorm_type, input_nc, semantic_nc)\n",
        "\n",
        "        self.relu = nn.LeakyReLU(0.2)\n",
        "\n",
        "    def shortcut(self, x, seg, misalign_mask):\n",
        "        if self.learned_shortcut:\n",
        "            return self.conv_s(self.norm_s(x, seg, misalign_mask))\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "    def forward(self, x, seg, misalign_mask=None):\n",
        "        seg = F.interpolate(seg, size=x.size()[2:], mode='nearest')\n",
        "        if misalign_mask is not None:\n",
        "            misalign_mask = F.interpolate(misalign_mask, size=x.size()[2:], mode='nearest')\n",
        "\n",
        "        x_s = self.shortcut(x, seg, misalign_mask)\n",
        "\n",
        "        dx = self.conv_0(self.relu(self.norm_0(x, seg, misalign_mask)))\n",
        "        dx = self.conv_1(self.relu(self.norm_1(dx, seg, misalign_mask)))\n",
        "        output = x_s + dx\n",
        "        return output"
      ],
      "metadata": {
        "id": "CGOqDISQforK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ALIASGenerator(BaseNetwork):\n",
        "    def __init__(self, opt, input_nc):\n",
        "        super(ALIASGenerator, self).__init__()\n",
        "        self.num_upsampling_layers = opt.num_upsampling_layers\n",
        "\n",
        "        self.sh, self.sw = self.compute_latent_vector_size(opt)\n",
        "\n",
        "        nf = opt.ngf\n",
        "        self.conv_0 = nn.Conv2d(input_nc, nf * 16, kernel_size=3, padding=1)\n",
        "        for i in range(1, 8):\n",
        "            self.add_module('conv_{}'.format(i), nn.Conv2d(input_nc, 16, kernel_size=3, padding=1))\n",
        "\n",
        "        self.head_0 = ALIASResBlock(opt, nf * 16, nf * 16)\n",
        "\n",
        "        self.G_middle_0 = ALIASResBlock(opt, nf * 16 + 16, nf * 16)\n",
        "        self.G_middle_1 = ALIASResBlock(opt, nf * 16 + 16, nf * 16)\n",
        "\n",
        "        self.up_0 = ALIASResBlock(opt, nf * 16 + 16, nf * 8)\n",
        "        self.up_1 = ALIASResBlock(opt, nf * 8 + 16, nf * 4)\n",
        "        self.up_2 = ALIASResBlock(opt, nf * 4 + 16, nf * 2, use_mask_norm=False)\n",
        "        self.up_3 = ALIASResBlock(opt, nf * 2 + 16, nf * 1, use_mask_norm=False)\n",
        "        if self.num_upsampling_layers == 'most':\n",
        "            self.up_4 = ALIASResBlock(opt, nf * 1 + 16, nf // 2, use_mask_norm=False)\n",
        "            nf = nf // 2\n",
        "\n",
        "        self.conv_img = nn.Conv2d(nf, 3, kernel_size=3, padding=1)\n",
        "\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.relu = nn.LeakyReLU(0.2)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "        self.print_network()\n",
        "        self.init_weights(opt.init_type, opt.init_variance)\n",
        "\n",
        "    def compute_latent_vector_size(self, opt):\n",
        "        if self.num_upsampling_layers == 'normal':\n",
        "            num_up_layers = 5\n",
        "        elif self.num_upsampling_layers == 'more':\n",
        "            num_up_layers = 6\n",
        "        elif self.num_upsampling_layers == 'most':\n",
        "            num_up_layers = 7\n",
        "        else:\n",
        "            raise ValueError(\"opt.num_upsampling_layers '{}' is not recognized\".format(self.num_upsampling_layers))\n",
        "\n",
        "        sh = opt.load_height // 2**num_up_layers\n",
        "        sw = opt.load_width // 2**num_up_layers\n",
        "        return sh, sw\n",
        "\n",
        "    def forward(self, x, seg, seg_div, misalign_mask):\n",
        "        samples = [F.interpolate(x, size=(self.sh * 2**i, self.sw * 2**i), mode='nearest') for i in range(8)]\n",
        "        features = [self._modules['conv_{}'.format(i)](samples[i]) for i in range(8)]\n",
        "\n",
        "        x = self.head_0(features[0], seg_div, misalign_mask)\n",
        "\n",
        "        x = self.up(x)\n",
        "        x = self.G_middle_0(torch.cat((x, features[1]), 1), seg_div, misalign_mask)\n",
        "        if self.num_upsampling_layers in ['more', 'most']:\n",
        "            x = self.up(x)\n",
        "        x = self.G_middle_1(torch.cat((x, features[2]), 1), seg_div, misalign_mask)\n",
        "\n",
        "        x = self.up(x)\n",
        "        x = self.up_0(torch.cat((x, features[3]), 1), seg_div, misalign_mask)\n",
        "        x = self.up(x)\n",
        "        x = self.up_1(torch.cat((x, features[4]), 1), seg_div, misalign_mask)\n",
        "        x = self.up(x)\n",
        "        x = self.up_2(torch.cat((x, features[5]), 1), seg)\n",
        "        x = self.up(x)\n",
        "        x = self.up_3(torch.cat((x, features[6]), 1), seg)\n",
        "        if self.num_upsampling_layers == 'most':\n",
        "            x = self.up(x)\n",
        "            x = self.up_4(torch.cat((x, features[7]), 1), seg)\n",
        "\n",
        "        x = self.conv_img(self.relu(x))\n",
        "        return self.tanh(x)"
      ],
      "metadata": {
        "id": "5PU-s5lvfs1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VITONDataset(data.Dataset):\n",
        "    def __init__(self, opt):\n",
        "        super(VITONDataset, self).__init__()\n",
        "        self.load_height = opt.load_height\n",
        "        self.load_width = opt.load_width\n",
        "        self.semantic_nc = opt.semantic_nc\n",
        "        self.data_path = osp.join(opt.dataset_dir, opt.dataset_mode)\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "        # load data list\n",
        "        img_names = []\n",
        "        c_names = []\n",
        "        with open(osp.join(opt.dataset_dir, opt.dataset_list), 'r') as f:\n",
        "            for line in f.readlines():\n",
        "                img_name, c_name = line.strip().split()\n",
        "                img_names.append(img_name)\n",
        "                c_names.append(c_name)\n",
        "\n",
        "        self.img_names = img_names\n",
        "        self.c_names = dict()\n",
        "        self.c_names['unpaired'] = c_names\n",
        "\n",
        "    def get_parse_agnostic(self, parse, pose_data):\n",
        "        parse_array = np.array(parse)\n",
        "        parse_upper = ((parse_array == 5).astype(np.float32) +\n",
        "                       (parse_array == 6).astype(np.float32) +\n",
        "                       (parse_array == 7).astype(np.float32))\n",
        "        parse_neck = (parse_array == 10).astype(np.float32)\n",
        "\n",
        "        r = 10\n",
        "        agnostic = parse.copy()\n",
        "\n",
        "        # mask arms\n",
        "        for parse_id, pose_ids in [(14, [2, 5, 6, 7]), (15, [5, 2, 3, 4])]:\n",
        "            mask_arm = Image.new('L', (self.load_width, self.load_height), 'black')\n",
        "            mask_arm_draw = ImageDraw.Draw(mask_arm)\n",
        "            i_prev = pose_ids[0]\n",
        "            for i in pose_ids[1:]:\n",
        "                if (pose_data[i_prev, 0] == 0.0 and pose_data[i_prev, 1] == 0.0) or (pose_data[i, 0] == 0.0 and pose_data[i, 1] == 0.0):\n",
        "                    continue\n",
        "                mask_arm_draw.line([tuple(pose_data[j]) for j in [i_prev, i]], 'white', width=r*10)\n",
        "                pointx, pointy = pose_data[i]\n",
        "                radius = r*4 if i == pose_ids[-1] else r*15\n",
        "                mask_arm_draw.ellipse((pointx-radius, pointy-radius, pointx+radius, pointy+radius), 'white', 'white')\n",
        "                i_prev = i\n",
        "            parse_arm = (np.array(mask_arm) / 255) * (parse_array == parse_id).astype(np.float32)\n",
        "            agnostic.paste(0, None, Image.fromarray(np.uint8(parse_arm * 255), 'L'))\n",
        "\n",
        "        # mask torso & neck\n",
        "        agnostic.paste(0, None, Image.fromarray(np.uint8(parse_upper * 255), 'L'))\n",
        "        agnostic.paste(0, None, Image.fromarray(np.uint8(parse_neck * 255), 'L'))\n",
        "\n",
        "        return agnostic\n",
        "\n",
        "    def get_img_agnostic(self, img, parse, pose_data):\n",
        "        parse_array = np.array(parse)\n",
        "        parse_head = ((parse_array == 4).astype(np.float32) +\n",
        "                      (parse_array == 13).astype(np.float32))\n",
        "        parse_lower = ((parse_array == 9).astype(np.float32) +\n",
        "                       (parse_array == 12).astype(np.float32) +\n",
        "                       (parse_array == 16).astype(np.float32) +\n",
        "                       (parse_array == 17).astype(np.float32) +\n",
        "                       (parse_array == 18).astype(np.float32) +\n",
        "                       (parse_array == 19).astype(np.float32))\n",
        "\n",
        "        r = 20\n",
        "        agnostic = img.copy()\n",
        "        agnostic_draw = ImageDraw.Draw(agnostic)\n",
        "\n",
        "        length_a = np.linalg.norm(pose_data[5] - pose_data[2])\n",
        "        length_b = np.linalg.norm(pose_data[12] - pose_data[9])\n",
        "        point = (pose_data[9] + pose_data[12]) / 2\n",
        "        pose_data[9] = point + (pose_data[9] - point) / length_b * length_a\n",
        "        pose_data[12] = point + (pose_data[12] - point) / length_b * length_a\n",
        "\n",
        "        # mask arms\n",
        "        agnostic_draw.line([tuple(pose_data[i]) for i in [2, 5]], 'gray', width=r*10)\n",
        "        for i in [2, 5]:\n",
        "            pointx, pointy = pose_data[i]\n",
        "            agnostic_draw.ellipse((pointx-r*5, pointy-r*5, pointx+r*5, pointy+r*5), 'gray', 'gray')\n",
        "        for i in [3, 4, 6, 7]:\n",
        "            if (pose_data[i - 1, 0] == 0.0 and pose_data[i - 1, 1] == 0.0) or (pose_data[i, 0] == 0.0 and pose_data[i, 1] == 0.0):\n",
        "                continue\n",
        "            agnostic_draw.line([tuple(pose_data[j]) for j in [i - 1, i]], 'gray', width=r*10)\n",
        "            pointx, pointy = pose_data[i]\n",
        "            agnostic_draw.ellipse((pointx-r*5, pointy-r*5, pointx+r*5, pointy+r*5), 'gray', 'gray')\n",
        "\n",
        "        # mask torso\n",
        "        for i in [9, 12]:\n",
        "            pointx, pointy = pose_data[i]\n",
        "            agnostic_draw.ellipse((pointx-r*3, pointy-r*6, pointx+r*3, pointy+r*6), 'gray', 'gray')\n",
        "        agnostic_draw.line([tuple(pose_data[i]) for i in [2, 9]], 'gray', width=r*6)\n",
        "        agnostic_draw.line([tuple(pose_data[i]) for i in [5, 12]], 'gray', width=r*6)\n",
        "        agnostic_draw.line([tuple(pose_data[i]) for i in [9, 12]], 'gray', width=r*12)\n",
        "        agnostic_draw.polygon([tuple(pose_data[i]) for i in [2, 5, 12, 9]], 'gray', 'gray')\n",
        "\n",
        "        # mask neck\n",
        "        pointx, pointy = pose_data[1]\n",
        "        agnostic_draw.rectangle((pointx-r*7, pointy-r*7, pointx+r*7, pointy+r*7), 'gray', 'gray')\n",
        "        agnostic.paste(img, None, Image.fromarray(np.uint8(parse_head * 255), 'L'))\n",
        "        agnostic.paste(img, None, Image.fromarray(np.uint8(parse_lower * 255), 'L'))\n",
        "\n",
        "        return agnostic\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name = self.img_names[index]\n",
        "        c_name = {}\n",
        "        c = {}\n",
        "        cm = {}\n",
        "        for key in self.c_names:\n",
        "            c_name[key] = self.c_names[key][index]\n",
        "            c[key] = Image.open(osp.join(self.data_path, 'cloth', c_name[key])).convert('RGB')\n",
        "            c[key] = transforms.Resize(self.load_width, interpolation=2)(c[key])\n",
        "            cm[key] = Image.open(osp.join(self.data_path, 'cloth-mask', c_name[key]))\n",
        "            cm[key] = transforms.Resize(self.load_width, interpolation=0)(cm[key])\n",
        "\n",
        "            c[key] = self.transform(c[key])  # [-1,1]\n",
        "            cm_array = np.array(cm[key])\n",
        "            cm_array = (cm_array >= 128).astype(np.float32)\n",
        "            cm[key] = torch.from_numpy(cm_array)  # [0,1]\n",
        "            cm[key].unsqueeze_(0)\n",
        "\n",
        "        # load pose image\n",
        "        pose_name = img_name.replace('.jpg', '_rendered.png')\n",
        "        pose_rgb = Image.open(osp.join(self.data_path, 'openpose-img', pose_name))\n",
        "        pose_rgb = transforms.Resize(self.load_width, interpolation=2)(pose_rgb)\n",
        "        pose_rgb = self.transform(pose_rgb)  # [-1,1]\n",
        "\n",
        "        pose_name = img_name.replace('.jpg', '_keypoints.json')\n",
        "        with open(osp.join(self.data_path, 'openpose-json', pose_name), 'r') as f:\n",
        "            pose_label = json.load(f)\n",
        "            pose_data = pose_label['people'][0]['pose_keypoints_2d']\n",
        "            pose_data = np.array(pose_data)\n",
        "            pose_data = pose_data.reshape((-1, 3))[:, :2]\n",
        "\n",
        "        # load parsing image\n",
        "        parse_name = img_name.replace('.jpg', '.png')\n",
        "        parse = Image.open(osp.join(self.data_path, 'image-parse', parse_name))\n",
        "        parse = transforms.Resize(self.load_width, interpolation=0)(parse)\n",
        "        parse_agnostic = self.get_parse_agnostic(parse, pose_data)\n",
        "        parse_agnostic = torch.from_numpy(np.array(parse_agnostic)[None]).long()\n",
        "\n",
        "        labels = {\n",
        "            0: ['background', [0, 10]],\n",
        "            1: ['hair', [1, 2]],\n",
        "            2: ['face', [4, 13]],\n",
        "            3: ['upper', [5, 6, 7]],\n",
        "            4: ['bottom', [9, 12]],\n",
        "            5: ['left_arm', [14]],\n",
        "            6: ['right_arm', [15]],\n",
        "            7: ['left_leg', [16]],\n",
        "            8: ['right_leg', [17]],\n",
        "            9: ['left_shoe', [18]],\n",
        "            10: ['right_shoe', [19]],\n",
        "            11: ['socks', [8]],\n",
        "            12: ['noise', [3, 11]]\n",
        "        }\n",
        "        parse_agnostic_map = torch.zeros(20, self.load_height, self.load_width, dtype=torch.float)\n",
        "        parse_agnostic_map.scatter_(0, parse_agnostic, 1.0)\n",
        "        new_parse_agnostic_map = torch.zeros(self.semantic_nc, self.load_height, self.load_width, dtype=torch.float)\n",
        "        for i in range(len(labels)):\n",
        "            for label in labels[i][1]:\n",
        "                new_parse_agnostic_map[i] += parse_agnostic_map[label]\n",
        "\n",
        "        # load person image\n",
        "        img = Image.open(osp.join(self.data_path, 'image', img_name))\n",
        "        img = transforms.Resize(self.load_width, interpolation=2)(img)\n",
        "        img_agnostic = self.get_img_agnostic(img, parse, pose_data)\n",
        "        img = self.transform(img)\n",
        "        img_agnostic = self.transform(img_agnostic)  # [-1,1]\n",
        "\n",
        "        result = {\n",
        "            'img_name': img_name,\n",
        "            'c_name': c_name,\n",
        "            'img': img,\n",
        "            'img_agnostic': img_agnostic,\n",
        "            'parse_agnostic': new_parse_agnostic_map,\n",
        "            'pose': pose_rgb,\n",
        "            'cloth': c,\n",
        "            'cloth_mask': cm,\n",
        "        }\n",
        "        return result\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_names)"
      ],
      "metadata": {
        "id": "sBCfNl5ffxFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VITONDataLoader:\n",
        "    def __init__(self, opt, dataset):\n",
        "        super(VITONDataLoader, self).__init__()\n",
        "\n",
        "        if opt.shuffle:\n",
        "            train_sampler = data.sampler.RandomSampler(dataset)\n",
        "        else:\n",
        "            train_sampler = None\n",
        "\n",
        "        self.data_loader = data.DataLoader(\n",
        "                dataset, batch_size=opt.batch_size, shuffle=(train_sampler is None),\n",
        "                num_workers=opt.workers, pin_memory=True, drop_last=True, sampler=train_sampler\n",
        "        )\n",
        "        self.dataset = dataset\n",
        "        self.data_iter = self.data_loader.__iter__()\n",
        "\n",
        "    def next_batch(self):\n",
        "        try:\n",
        "            batch = self.data_iter.__next__()\n",
        "        except StopIteration:\n",
        "            self.data_iter = self.data_loader.__iter__()\n",
        "            batch = self.data_iter.__next__()\n",
        "\n",
        "        return batch"
      ],
      "metadata": {
        "id": "EtOpkEJqgSOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_noise(shape):\n",
        "    noise = np.zeros(shape, dtype=np.uint8)\n",
        "    ### noise\n",
        "    noise = cv2.randn(noise, 0, 255)\n",
        "    noise = np.asarray(noise / 255, dtype=np.uint8)\n",
        "    noise = torch.tensor(noise, dtype=torch.float32)\n",
        "    return noise"
      ],
      "metadata": {
        "id": "lpw6wjTigkg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_images(img_tensors, img_names, save_dir):\n",
        "    for img_tensor, img_name in zip(img_tensors, img_names):\n",
        "        tensor = (img_tensor.clone()+1)*0.5 * 255\n",
        "        tensor = tensor.cpu().clamp(0,255)\n",
        "\n",
        "        try:\n",
        "            array = tensor.numpy().astype('uint8')\n",
        "        except:\n",
        "            array = tensor.detach().numpy().astype('uint8')\n",
        "\n",
        "        if array.shape[0] == 1:\n",
        "            array = array.squeeze(0)\n",
        "        elif array.shape[0] == 3:\n",
        "            array = array.swapaxes(0, 1).swapaxes(1, 2)\n",
        "\n",
        "        im = Image.fromarray(array)\n",
        "        im.save(os.path.join(save_dir, img_name), format='JPEG')"
      ],
      "metadata": {
        "id": "rtL1RJfxhpTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(model, checkpoint_path):\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        raise ValueError(\"'{}' is not a valid checkpoint path\".format(checkpoint_path))\n",
        "    model.load_state_dict(torch.load(checkpoint_path))"
      ],
      "metadata": {
        "id": "Scg9KxSFhzdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_opt():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--name', type=str, default='results')\n",
        "\n",
        "    parser.add_argument('-b', '--batch_size', type=int, default=1)\n",
        "    parser.add_argument('-j', '--workers', type=int, default=1)\n",
        "    parser.add_argument('--load_height', type=int, default=1024)\n",
        "    parser.add_argument('--load_width', type=int, default=768)\n",
        "    parser.add_argument('--shuffle', action='store_true')\n",
        "\n",
        "    parser.add_argument('--dataset_dir', type=str, default='./drive/MyDrive/datasets/')\n",
        "    parser.add_argument('--dataset_mode', type=str, default='test')\n",
        "    parser.add_argument('--dataset_list', type=str, default='test_pairs.txt')\n",
        "    parser.add_argument('--checkpoint_dir', type=str, default='./drive/MyDrive/checkpoints/')\n",
        "    parser.add_argument('--save_dir', type=str, default='./results/')\n",
        "\n",
        "    parser.add_argument('--display_freq', type=int, default=1)\n",
        "\n",
        "    parser.add_argument('--seg_checkpoint', type=str, default='seg_final.pth')\n",
        "    parser.add_argument('--gmm_checkpoint', type=str, default='gmm_final.pth')\n",
        "    parser.add_argument('--alias_checkpoint', type=str, default='alias_final.pth')\n",
        "\n",
        "    # common\n",
        "    parser.add_argument('--semantic_nc', type=int, default=13, help='# of human-parsing map classes')\n",
        "    parser.add_argument('--init_type', choices=['normal', 'xavier', 'xavier_uniform', 'kaiming', 'orthogonal', 'none'], default='xavier')\n",
        "    parser.add_argument('--init_variance', type=float, default=0.02, help='variance of the initialization distribution')\n",
        "\n",
        "    # for GMM\n",
        "    parser.add_argument('--grid_size', type=int, default=5)\n",
        "\n",
        "    # for ALIASGenerator\n",
        "    parser.add_argument('--norm_G', type=str, default='spectralaliasinstance')\n",
        "    parser.add_argument('--ngf', type=int, default=64, help='# of generator filters in the first conv layer')\n",
        "    parser.add_argument('--num_upsampling_layers', choices=['normal', 'more', 'most'], default='most',\n",
        "                        help='If \\'more\\', add upsampling layer between the two middle resnet blocks. '\n",
        "                             'If \\'most\\', also add one more (upsampling + resnet) layer at the end of the generator.')\n",
        "\n",
        "    opt = parser.parse_args()\n",
        "    return opt"
      ],
      "metadata": {
        "id": "jGXnzg98kmYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(opt, seg, gmm, alias):\n",
        "    up = nn.Upsample(size=(opt.load_height, opt.load_width), mode='bilinear')\n",
        "    gauss = tgm.image.GaussianBlur((15, 15), (3, 3))\n",
        "    gauss.cuda()\n",
        "\n",
        "    test_dataset = VITONDataset(opt)\n",
        "    test_loader = VITONDataLoader(opt, test_dataset)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, inputs in enumerate(test_loader.data_loader):\n",
        "            img_names = inputs['img_name']\n",
        "            c_names = inputs['c_name']['unpaired']\n",
        "\n",
        "            img_agnostic = inputs['img_agnostic'].cuda()\n",
        "            parse_agnostic = inputs['parse_agnostic'].cuda()\n",
        "            pose = inputs['pose'].cuda()\n",
        "            c = inputs['cloth']['unpaired'].cuda()\n",
        "            cm = inputs['cloth_mask']['unpaired'].cuda()\n",
        "\n",
        "            # Part 1. Segmentation generation\n",
        "            parse_agnostic_down = F.interpolate(parse_agnostic, size=(256, 192), mode='bilinear')\n",
        "            pose_down = F.interpolate(pose, size=(256, 192), mode='bilinear')\n",
        "            c_masked_down = F.interpolate(c * cm, size=(256, 192), mode='bilinear')\n",
        "            cm_down = F.interpolate(cm, size=(256, 192), mode='bilinear')\n",
        "            seg_input = torch.cat((cm_down, c_masked_down, parse_agnostic_down, pose_down, gen_noise(cm_down.size()).cuda()), dim=1)\n",
        "\n",
        "            parse_pred_down = seg(seg_input)\n",
        "            parse_pred = gauss(up(parse_pred_down))\n",
        "            parse_pred = parse_pred.argmax(dim=1)[:, None]\n",
        "\n",
        "            parse_old = torch.zeros(parse_pred.size(0), 13, opt.load_height, opt.load_width, dtype=torch.float).cuda()\n",
        "            parse_old.scatter_(1, parse_pred, 1.0)\n",
        "\n",
        "            labels = {\n",
        "                0:  ['background',  [0]],\n",
        "                1:  ['paste',       [2, 4, 7, 8, 9, 10, 11]],\n",
        "                2:  ['upper',       [3]],\n",
        "                3:  ['hair',        [1]],\n",
        "                4:  ['left_arm',    [5]],\n",
        "                5:  ['right_arm',   [6]],\n",
        "                6:  ['noise',       [12]]\n",
        "            }\n",
        "            parse = torch.zeros(parse_pred.size(0), 7, opt.load_height, opt.load_width, dtype=torch.float).cuda()\n",
        "            for j in range(len(labels)):\n",
        "                for label in labels[j][1]:\n",
        "                    parse[:, j] += parse_old[:, label]\n",
        "\n",
        "            # Part 2. Clothes Deformation\n",
        "            agnostic_gmm = F.interpolate(img_agnostic, size=(256, 192), mode='nearest')\n",
        "            parse_cloth_gmm = F.interpolate(parse[:, 2:3], size=(256, 192), mode='nearest')\n",
        "            pose_gmm = F.interpolate(pose, size=(256, 192), mode='nearest')\n",
        "            c_gmm = F.interpolate(c, size=(256, 192), mode='nearest')\n",
        "            gmm_input = torch.cat((parse_cloth_gmm, pose_gmm, agnostic_gmm), dim=1)\n",
        "\n",
        "            _, warped_grid = gmm(gmm_input, c_gmm)\n",
        "            warped_c = F.grid_sample(c, warped_grid, padding_mode='border')\n",
        "            warped_cm = F.grid_sample(cm, warped_grid, padding_mode='border')\n",
        "\n",
        "            # Part 3. Try-on synthesis\n",
        "            misalign_mask = parse[:, 2:3] - warped_cm\n",
        "            misalign_mask[misalign_mask < 0.0] = 0.0\n",
        "            parse_div = torch.cat((parse, misalign_mask), dim=1)\n",
        "            parse_div[:, 2:3] -= misalign_mask\n",
        "\n",
        "            output = alias(torch.cat((img_agnostic, pose, warped_c), dim=1), parse, parse_div, misalign_mask)\n",
        "\n",
        "            unpaired_names = []\n",
        "            for img_name, c_name in zip(img_names, c_names):\n",
        "                unpaired_names.append('{}_{}'.format(img_name.split('_')[0], c_name))\n",
        "\n",
        "            save_images(output, unpaired_names, os.path.join(opt.save_dir, opt.name))\n",
        "\n",
        "            if (i + 1) % opt.display_freq == 0:\n",
        "                print(\"step: {}\".format(i + 1))"
      ],
      "metadata": {
        "id": "_olDtORmlapn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.argv=['']\n",
        "del sys"
      ],
      "metadata": {
        "id": "exgHWYa2nbif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = get_opt()"
      ],
      "metadata": {
        "id": "KH84XCySlfr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(os.path.join(opt.save_dir, opt.name)):\n",
        "  os.makedirs(os.path.join(opt.save_dir, opt.name))"
      ],
      "metadata": {
        "id": "h3eQYg1ntU0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seg = SegGenerator(opt, input_nc=opt.semantic_nc + 8, output_nc=opt.semantic_nc)\n",
        "gmm = GMM(opt, inputA_nc=7, inputB_nc=3)\n",
        "opt.semantic_nc = 7\n",
        "alias = ALIASGenerator(opt, input_nc=9)\n",
        "opt.semantic_nc = 13"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHM8jXhyn80o",
        "outputId": "d939fbd1-cdfa-40c6-daca-6d4a76ca9c67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Network [SegGenerator] was created. Total number of parameters: 34.5 million. To see the architecture, do print(network).\n",
            "Network [ALIASGenerator] was created. Total number of parameters: 100.5 million. To see the architecture, do print(network).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_checkpoint(seg, os.path.join(opt.checkpoint_dir, opt.seg_checkpoint))\n",
        "load_checkpoint(gmm, os.path.join(opt.checkpoint_dir, opt.gmm_checkpoint))\n",
        "load_checkpoint(alias, os.path.join(opt.checkpoint_dir, opt.alias_checkpoint))"
      ],
      "metadata": {
        "id": "oKf8RsoepmXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seg.cuda().eval()\n",
        "gmm.cuda().eval()\n",
        "alias.cuda().eval()\n",
        "test(opt, seg, gmm, alias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7-oGWyJs4H8",
        "outputId": "a4060799-744e-4bcd-e6dd-506582bfbe0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9230533050>\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9230533050>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9230533050>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9230533050>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  \"Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. \"\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9230533050>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9230533050>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9230533050>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9230533050>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1481, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1464, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:4216: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
            "  \"Default grid_sample and affine_grid behavior has changed \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 1\n",
            "step: 2\n",
            "step: 3\n",
            "step: 4\n",
            "step: 5\n",
            "step: 6\n",
            "step: 7\n",
            "step: 8\n",
            "step: 9\n",
            "step: 10\n",
            "step: 11\n",
            "step: 12\n",
            "step: 13\n",
            "step: 14\n",
            "step: 15\n",
            "step: 16\n",
            "step: 17\n",
            "step: 18\n",
            "step: 19\n",
            "step: 20\n",
            "step: 21\n",
            "step: 22\n",
            "step: 23\n",
            "step: 24\n",
            "step: 25\n",
            "step: 26\n",
            "step: 27\n",
            "step: 28\n",
            "step: 29\n",
            "step: 30\n",
            "step: 31\n",
            "step: 32\n",
            "step: 33\n",
            "step: 34\n",
            "step: 35\n",
            "step: 36\n",
            "step: 37\n",
            "step: 38\n",
            "step: 39\n",
            "step: 40\n",
            "step: 41\n",
            "step: 42\n",
            "step: 43\n",
            "step: 44\n",
            "step: 45\n",
            "step: 46\n",
            "step: 47\n",
            "step: 48\n",
            "step: 49\n",
            "step: 50\n",
            "step: 51\n",
            "step: 52\n",
            "step: 53\n",
            "step: 54\n",
            "step: 55\n",
            "step: 56\n",
            "step: 57\n",
            "step: 58\n",
            "step: 59\n",
            "step: 60\n",
            "step: 61\n",
            "step: 62\n",
            "step: 63\n",
            "step: 64\n",
            "step: 65\n",
            "step: 66\n",
            "step: 67\n",
            "step: 68\n",
            "step: 69\n",
            "step: 70\n",
            "step: 71\n",
            "step: 72\n",
            "step: 73\n",
            "step: 74\n",
            "step: 75\n",
            "step: 76\n",
            "step: 77\n",
            "step: 78\n",
            "step: 79\n",
            "step: 80\n",
            "step: 81\n",
            "step: 82\n",
            "step: 83\n",
            "step: 84\n",
            "step: 85\n",
            "step: 86\n",
            "step: 87\n",
            "step: 88\n",
            "step: 89\n",
            "step: 90\n",
            "step: 91\n",
            "step: 92\n",
            "step: 93\n",
            "step: 94\n",
            "step: 95\n",
            "step: 96\n",
            "step: 97\n",
            "step: 98\n",
            "step: 99\n",
            "step: 100\n",
            "step: 101\n",
            "step: 102\n",
            "step: 103\n",
            "step: 104\n",
            "step: 105\n",
            "step: 106\n",
            "step: 107\n",
            "step: 108\n",
            "step: 109\n",
            "step: 110\n",
            "step: 111\n",
            "step: 112\n",
            "step: 113\n",
            "step: 114\n",
            "step: 115\n",
            "step: 116\n",
            "step: 117\n",
            "step: 118\n",
            "step: 119\n",
            "step: 120\n",
            "step: 121\n",
            "step: 122\n",
            "step: 123\n",
            "step: 124\n",
            "step: 125\n",
            "step: 126\n",
            "step: 127\n",
            "step: 128\n",
            "step: 129\n",
            "step: 130\n",
            "step: 131\n",
            "step: 132\n",
            "step: 133\n",
            "step: 134\n",
            "step: 135\n",
            "step: 136\n",
            "step: 137\n",
            "step: 138\n",
            "step: 139\n",
            "step: 140\n",
            "step: 141\n",
            "step: 142\n",
            "step: 143\n",
            "step: 144\n",
            "step: 145\n",
            "step: 146\n",
            "step: 147\n",
            "step: 148\n",
            "step: 149\n",
            "step: 150\n",
            "step: 151\n",
            "step: 152\n",
            "step: 153\n",
            "step: 154\n",
            "step: 155\n",
            "step: 156\n",
            "step: 157\n",
            "step: 158\n",
            "step: 159\n",
            "step: 160\n",
            "step: 161\n",
            "step: 162\n",
            "step: 163\n",
            "step: 164\n",
            "step: 165\n",
            "step: 166\n",
            "step: 167\n",
            "step: 168\n",
            "step: 169\n",
            "step: 170\n",
            "step: 171\n",
            "step: 172\n",
            "step: 173\n",
            "step: 174\n",
            "step: 175\n",
            "step: 176\n",
            "step: 177\n",
            "step: 178\n",
            "step: 179\n",
            "step: 180\n",
            "step: 181\n",
            "step: 182\n",
            "step: 183\n",
            "step: 184\n",
            "step: 185\n",
            "step: 186\n",
            "step: 187\n",
            "step: 188\n",
            "step: 189\n",
            "step: 190\n",
            "step: 191\n",
            "step: 192\n",
            "step: 193\n",
            "step: 194\n",
            "step: 195\n",
            "step: 196\n",
            "step: 197\n",
            "step: 198\n",
            "step: 199\n",
            "step: 200\n",
            "step: 201\n",
            "step: 202\n",
            "step: 203\n",
            "step: 204\n",
            "step: 205\n",
            "step: 206\n",
            "step: 207\n",
            "step: 208\n",
            "step: 209\n",
            "step: 210\n",
            "step: 211\n",
            "step: 212\n",
            "step: 213\n",
            "step: 214\n",
            "step: 215\n",
            "step: 216\n",
            "step: 217\n",
            "step: 218\n",
            "step: 219\n",
            "step: 220\n",
            "step: 221\n",
            "step: 222\n",
            "step: 223\n",
            "step: 224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "__main__:76: RuntimeWarning: invalid value encountered in true_divide\n",
            "__main__:77: RuntimeWarning: invalid value encountered in true_divide\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 225\n",
            "step: 226\n",
            "step: 227\n",
            "step: 228\n",
            "step: 229\n",
            "step: 230\n",
            "step: 231\n",
            "step: 232\n",
            "step: 233\n",
            "step: 234\n",
            "step: 235\n",
            "step: 236\n",
            "step: 237\n",
            "step: 238\n",
            "step: 239\n",
            "step: 240\n",
            "step: 241\n",
            "step: 242\n",
            "step: 243\n",
            "step: 244\n",
            "step: 245\n",
            "step: 246\n",
            "step: 247\n",
            "step: 248\n",
            "step: 249\n",
            "step: 250\n",
            "step: 251\n",
            "step: 252\n",
            "step: 253\n",
            "step: 254\n",
            "step: 255\n",
            "step: 256\n",
            "step: 257\n",
            "step: 258\n",
            "step: 259\n",
            "step: 260\n",
            "step: 261\n",
            "step: 262\n",
            "step: 263\n",
            "step: 264\n",
            "step: 265\n",
            "step: 266\n",
            "step: 267\n",
            "step: 268\n",
            "step: 269\n",
            "step: 270\n",
            "step: 271\n",
            "step: 272\n",
            "step: 273\n",
            "step: 274\n",
            "step: 275\n",
            "step: 276\n",
            "step: 277\n",
            "step: 278\n",
            "step: 279\n",
            "step: 280\n",
            "step: 281\n",
            "step: 282\n",
            "step: 283\n",
            "step: 284\n",
            "step: 285\n",
            "step: 286\n",
            "step: 287\n",
            "step: 288\n",
            "step: 289\n",
            "step: 290\n",
            "step: 291\n",
            "step: 292\n",
            "step: 293\n",
            "step: 294\n",
            "step: 295\n",
            "step: 296\n",
            "step: 297\n",
            "step: 298\n",
            "step: 299\n",
            "step: 300\n",
            "step: 301\n",
            "step: 302\n",
            "step: 303\n",
            "step: 304\n",
            "step: 305\n",
            "step: 306\n",
            "step: 307\n",
            "step: 308\n",
            "step: 309\n",
            "step: 310\n",
            "step: 311\n",
            "step: 312\n",
            "step: 313\n",
            "step: 314\n",
            "step: 315\n",
            "step: 316\n",
            "step: 317\n",
            "step: 318\n",
            "step: 319\n",
            "step: 320\n",
            "step: 321\n",
            "step: 322\n",
            "step: 323\n",
            "step: 324\n",
            "step: 325\n",
            "step: 326\n",
            "step: 327\n",
            "step: 328\n",
            "step: 329\n",
            "step: 330\n",
            "step: 331\n",
            "step: 332\n",
            "step: 333\n",
            "step: 334\n",
            "step: 335\n",
            "step: 336\n",
            "step: 337\n",
            "step: 338\n",
            "step: 339\n",
            "step: 340\n",
            "step: 341\n",
            "step: 342\n",
            "step: 343\n",
            "step: 344\n",
            "step: 345\n",
            "step: 346\n",
            "step: 347\n",
            "step: 348\n",
            "step: 349\n",
            "step: 350\n",
            "step: 351\n",
            "step: 352\n",
            "step: 353\n",
            "step: 354\n",
            "step: 355\n",
            "step: 356\n",
            "step: 357\n",
            "step: 358\n",
            "step: 359\n",
            "step: 360\n",
            "step: 361\n",
            "step: 362\n",
            "step: 363\n",
            "step: 364\n",
            "step: 365\n",
            "step: 366\n",
            "step: 367\n",
            "step: 368\n",
            "step: 369\n",
            "step: 370\n",
            "step: 371\n",
            "step: 372\n",
            "step: 373\n",
            "step: 374\n",
            "step: 375\n",
            "step: 376\n",
            "step: 377\n",
            "step: 378\n",
            "step: 379\n",
            "step: 380\n",
            "step: 381\n",
            "step: 382\n",
            "step: 383\n",
            "step: 384\n",
            "step: 385\n",
            "step: 386\n",
            "step: 387\n",
            "step: 388\n",
            "step: 389\n",
            "step: 390\n",
            "step: 391\n",
            "step: 392\n",
            "step: 393\n",
            "step: 394\n",
            "step: 395\n",
            "step: 396\n",
            "step: 397\n",
            "step: 398\n",
            "step: 399\n",
            "step: 400\n",
            "step: 401\n",
            "step: 402\n",
            "step: 403\n",
            "step: 404\n",
            "step: 405\n",
            "step: 406\n",
            "step: 407\n",
            "step: 408\n",
            "step: 409\n",
            "step: 410\n",
            "step: 411\n",
            "step: 412\n",
            "step: 413\n",
            "step: 414\n",
            "step: 415\n",
            "step: 416\n",
            "step: 417\n",
            "step: 418\n",
            "step: 419\n",
            "step: 420\n",
            "step: 421\n",
            "step: 422\n",
            "step: 423\n",
            "step: 424\n",
            "step: 425\n",
            "step: 426\n",
            "step: 427\n",
            "step: 428\n",
            "step: 429\n",
            "step: 430\n",
            "step: 431\n",
            "step: 432\n",
            "step: 433\n",
            "step: 434\n",
            "step: 435\n",
            "step: 436\n",
            "step: 437\n",
            "step: 438\n",
            "step: 439\n",
            "step: 440\n",
            "step: 441\n",
            "step: 442\n",
            "step: 443\n",
            "step: 444\n",
            "step: 445\n",
            "step: 446\n",
            "step: 447\n",
            "step: 448\n",
            "step: 449\n",
            "step: 450\n",
            "step: 451\n",
            "step: 452\n",
            "step: 453\n",
            "step: 454\n",
            "step: 455\n",
            "step: 456\n",
            "step: 457\n",
            "step: 458\n",
            "step: 459\n",
            "step: 460\n",
            "step: 461\n",
            "step: 462\n",
            "step: 463\n",
            "step: 464\n",
            "step: 465\n",
            "step: 466\n",
            "step: 467\n",
            "step: 468\n",
            "step: 469\n",
            "step: 470\n",
            "step: 471\n",
            "step: 472\n",
            "step: 473\n",
            "step: 474\n",
            "step: 475\n",
            "step: 476\n",
            "step: 477\n",
            "step: 478\n",
            "step: 479\n",
            "step: 480\n",
            "step: 481\n",
            "step: 482\n",
            "step: 483\n",
            "step: 484\n",
            "step: 485\n",
            "step: 486\n",
            "step: 487\n",
            "step: 488\n",
            "step: 489\n",
            "step: 490\n",
            "step: 491\n",
            "step: 492\n",
            "step: 493\n",
            "step: 494\n",
            "step: 495\n",
            "step: 496\n",
            "step: 497\n",
            "step: 498\n",
            "step: 499\n",
            "step: 500\n",
            "step: 501\n",
            "step: 502\n",
            "step: 503\n",
            "step: 504\n",
            "step: 505\n",
            "step: 506\n",
            "step: 507\n",
            "step: 508\n",
            "step: 509\n",
            "step: 510\n",
            "step: 511\n",
            "step: 512\n",
            "step: 513\n",
            "step: 514\n",
            "step: 515\n",
            "step: 516\n",
            "step: 517\n",
            "step: 518\n",
            "step: 519\n",
            "step: 520\n",
            "step: 521\n",
            "step: 522\n",
            "step: 523\n",
            "step: 524\n",
            "step: 525\n",
            "step: 526\n",
            "step: 527\n",
            "step: 528\n",
            "step: 529\n",
            "step: 530\n",
            "step: 531\n",
            "step: 532\n",
            "step: 533\n",
            "step: 534\n",
            "step: 535\n",
            "step: 536\n",
            "step: 537\n",
            "step: 538\n",
            "step: 539\n",
            "step: 540\n",
            "step: 541\n",
            "step: 542\n",
            "step: 543\n",
            "step: 544\n",
            "step: 545\n",
            "step: 546\n",
            "step: 547\n",
            "step: 548\n",
            "step: 549\n",
            "step: 550\n",
            "step: 551\n",
            "step: 552\n",
            "step: 553\n",
            "step: 554\n",
            "step: 555\n",
            "step: 556\n",
            "step: 557\n",
            "step: 558\n",
            "step: 559\n",
            "step: 560\n",
            "step: 561\n",
            "step: 562\n",
            "step: 563\n",
            "step: 564\n",
            "step: 565\n",
            "step: 566\n",
            "step: 567\n",
            "step: 568\n",
            "step: 569\n",
            "step: 570\n",
            "step: 571\n",
            "step: 572\n",
            "step: 573\n",
            "step: 574\n",
            "step: 575\n",
            "step: 576\n",
            "step: 577\n",
            "step: 578\n",
            "step: 579\n",
            "step: 580\n",
            "step: 581\n",
            "step: 582\n",
            "step: 583\n",
            "step: 584\n",
            "step: 585\n",
            "step: 586\n",
            "step: 587\n",
            "step: 588\n",
            "step: 589\n",
            "step: 590\n",
            "step: 591\n",
            "step: 592\n",
            "step: 593\n",
            "step: 594\n",
            "step: 595\n",
            "step: 596\n",
            "step: 597\n",
            "step: 598\n",
            "step: 599\n",
            "step: 600\n",
            "step: 601\n",
            "step: 602\n",
            "step: 603\n",
            "step: 604\n",
            "step: 605\n",
            "step: 606\n",
            "step: 607\n",
            "step: 608\n",
            "step: 609\n",
            "step: 610\n",
            "step: 611\n",
            "step: 612\n",
            "step: 613\n",
            "step: 614\n",
            "step: 615\n",
            "step: 616\n",
            "step: 617\n",
            "step: 618\n",
            "step: 619\n",
            "step: 620\n",
            "step: 621\n",
            "step: 622\n",
            "step: 623\n",
            "step: 624\n",
            "step: 625\n",
            "step: 626\n",
            "step: 627\n",
            "step: 628\n",
            "step: 629\n",
            "step: 630\n",
            "step: 631\n",
            "step: 632\n",
            "step: 633\n",
            "step: 634\n",
            "step: 635\n",
            "step: 636\n",
            "step: 637\n",
            "step: 638\n",
            "step: 639\n",
            "step: 640\n",
            "step: 641\n",
            "step: 642\n",
            "step: 643\n",
            "step: 644\n",
            "step: 645\n",
            "step: 646\n",
            "step: 647\n",
            "step: 648\n",
            "step: 649\n",
            "step: 650\n",
            "step: 651\n",
            "step: 652\n",
            "step: 653\n",
            "step: 654\n",
            "step: 655\n",
            "step: 656\n",
            "step: 657\n",
            "step: 658\n",
            "step: 659\n",
            "step: 660\n",
            "step: 661\n",
            "step: 662\n",
            "step: 663\n",
            "step: 664\n",
            "step: 665\n",
            "step: 666\n",
            "step: 667\n",
            "step: 668\n",
            "step: 669\n",
            "step: 670\n",
            "step: 671\n",
            "step: 672\n",
            "step: 673\n",
            "step: 674\n",
            "step: 675\n",
            "step: 676\n",
            "step: 677\n",
            "step: 678\n",
            "step: 679\n",
            "step: 680\n",
            "step: 681\n",
            "step: 682\n",
            "step: 683\n",
            "step: 684\n",
            "step: 685\n",
            "step: 686\n",
            "step: 687\n",
            "step: 688\n",
            "step: 689\n",
            "step: 690\n",
            "step: 691\n",
            "step: 692\n",
            "step: 693\n",
            "step: 694\n",
            "step: 695\n",
            "step: 696\n",
            "step: 697\n",
            "step: 698\n",
            "step: 699\n",
            "step: 700\n",
            "step: 701\n",
            "step: 702\n",
            "step: 703\n",
            "step: 704\n",
            "step: 705\n",
            "step: 706\n",
            "step: 707\n",
            "step: 708\n",
            "step: 709\n",
            "step: 710\n",
            "step: 711\n",
            "step: 712\n",
            "step: 713\n",
            "step: 714\n",
            "step: 715\n",
            "step: 716\n",
            "step: 717\n",
            "step: 718\n",
            "step: 719\n",
            "step: 720\n",
            "step: 721\n",
            "step: 722\n",
            "step: 723\n",
            "step: 724\n",
            "step: 725\n",
            "step: 726\n",
            "step: 727\n",
            "step: 728\n",
            "step: 729\n",
            "step: 730\n",
            "step: 731\n",
            "step: 732\n",
            "step: 733\n",
            "step: 734\n",
            "step: 735\n",
            "step: 736\n",
            "step: 737\n",
            "step: 738\n",
            "step: 739\n",
            "step: 740\n",
            "step: 741\n",
            "step: 742\n",
            "step: 743\n",
            "step: 744\n",
            "step: 745\n",
            "step: 746\n",
            "step: 747\n",
            "step: 748\n",
            "step: 749\n",
            "step: 750\n",
            "step: 751\n",
            "step: 752\n",
            "step: 753\n",
            "step: 754\n",
            "step: 755\n",
            "step: 756\n",
            "step: 757\n",
            "step: 758\n",
            "step: 759\n",
            "step: 760\n",
            "step: 761\n",
            "step: 762\n",
            "step: 763\n",
            "step: 764\n",
            "step: 765\n",
            "step: 766\n",
            "step: 767\n",
            "step: 768\n",
            "step: 769\n",
            "step: 770\n",
            "step: 771\n",
            "step: 772\n",
            "step: 773\n",
            "step: 774\n",
            "step: 775\n",
            "step: 776\n",
            "step: 777\n",
            "step: 778\n",
            "step: 779\n",
            "step: 780\n",
            "step: 781\n",
            "step: 782\n",
            "step: 783\n",
            "step: 784\n",
            "step: 785\n",
            "step: 786\n",
            "step: 787\n",
            "step: 788\n",
            "step: 789\n",
            "step: 790\n",
            "step: 791\n",
            "step: 792\n",
            "step: 793\n",
            "step: 794\n",
            "step: 795\n",
            "step: 796\n",
            "step: 797\n",
            "step: 798\n",
            "step: 799\n",
            "step: 800\n",
            "step: 801\n",
            "step: 802\n",
            "step: 803\n",
            "step: 804\n",
            "step: 805\n",
            "step: 806\n",
            "step: 807\n",
            "step: 808\n",
            "step: 809\n",
            "step: 810\n",
            "step: 811\n",
            "step: 812\n",
            "step: 813\n",
            "step: 814\n",
            "step: 815\n",
            "step: 816\n",
            "step: 817\n",
            "step: 818\n",
            "step: 819\n",
            "step: 820\n",
            "step: 821\n",
            "step: 822\n",
            "step: 823\n",
            "step: 824\n",
            "step: 825\n",
            "step: 826\n",
            "step: 827\n",
            "step: 828\n",
            "step: 829\n",
            "step: 830\n",
            "step: 831\n",
            "step: 832\n",
            "step: 833\n",
            "step: 834\n",
            "step: 835\n",
            "step: 836\n",
            "step: 837\n",
            "step: 838\n",
            "step: 839\n",
            "step: 840\n",
            "step: 841\n",
            "step: 842\n",
            "step: 843\n",
            "step: 844\n",
            "step: 845\n",
            "step: 846\n",
            "step: 847\n",
            "step: 848\n",
            "step: 849\n",
            "step: 850\n",
            "step: 851\n",
            "step: 852\n",
            "step: 853\n",
            "step: 854\n",
            "step: 855\n",
            "step: 856\n",
            "step: 857\n",
            "step: 858\n",
            "step: 859\n",
            "step: 860\n",
            "step: 861\n",
            "step: 862\n",
            "step: 863\n",
            "step: 864\n",
            "step: 865\n",
            "step: 866\n",
            "step: 867\n",
            "step: 868\n",
            "step: 869\n",
            "step: 870\n",
            "step: 871\n",
            "step: 872\n",
            "step: 873\n",
            "step: 874\n",
            "step: 875\n",
            "step: 876\n",
            "step: 877\n",
            "step: 878\n",
            "step: 879\n",
            "step: 880\n",
            "step: 881\n",
            "step: 882\n",
            "step: 883\n",
            "step: 884\n",
            "step: 885\n",
            "step: 886\n",
            "step: 887\n",
            "step: 888\n",
            "step: 889\n",
            "step: 890\n",
            "step: 891\n",
            "step: 892\n",
            "step: 893\n",
            "step: 894\n",
            "step: 895\n",
            "step: 896\n",
            "step: 897\n",
            "step: 898\n",
            "step: 899\n",
            "step: 900\n",
            "step: 901\n",
            "step: 902\n",
            "step: 903\n",
            "step: 904\n",
            "step: 905\n",
            "step: 906\n",
            "step: 907\n",
            "step: 908\n",
            "step: 909\n",
            "step: 910\n",
            "step: 911\n",
            "step: 912\n",
            "step: 913\n",
            "step: 914\n",
            "step: 915\n",
            "step: 916\n",
            "step: 917\n",
            "step: 918\n",
            "step: 919\n",
            "step: 920\n",
            "step: 921\n",
            "step: 922\n",
            "step: 923\n",
            "step: 924\n",
            "step: 925\n",
            "step: 926\n",
            "step: 927\n",
            "step: 928\n",
            "step: 929\n",
            "step: 930\n",
            "step: 931\n",
            "step: 932\n",
            "step: 933\n",
            "step: 934\n",
            "step: 935\n",
            "step: 936\n",
            "step: 937\n",
            "step: 938\n",
            "step: 939\n",
            "step: 940\n",
            "step: 941\n",
            "step: 942\n",
            "step: 943\n",
            "step: 944\n",
            "step: 945\n",
            "step: 946\n",
            "step: 947\n",
            "step: 948\n",
            "step: 949\n",
            "step: 950\n",
            "step: 951\n",
            "step: 952\n",
            "step: 953\n",
            "step: 954\n",
            "step: 955\n",
            "step: 956\n",
            "step: 957\n",
            "step: 958\n",
            "step: 959\n",
            "step: 960\n",
            "step: 961\n",
            "step: 962\n",
            "step: 963\n",
            "step: 964\n",
            "step: 965\n",
            "step: 966\n",
            "step: 967\n",
            "step: 968\n",
            "step: 969\n",
            "step: 970\n",
            "step: 971\n",
            "step: 972\n",
            "step: 973\n",
            "step: 974\n",
            "step: 975\n",
            "step: 976\n",
            "step: 977\n",
            "step: 978\n",
            "step: 979\n",
            "step: 980\n",
            "step: 981\n",
            "step: 982\n",
            "step: 983\n",
            "step: 984\n",
            "step: 985\n",
            "step: 986\n",
            "step: 987\n",
            "step: 988\n",
            "step: 989\n",
            "step: 990\n",
            "step: 991\n",
            "step: 992\n",
            "step: 993\n",
            "step: 994\n",
            "step: 995\n",
            "step: 996\n",
            "step: 997\n",
            "step: 998\n",
            "step: 999\n",
            "step: 1000\n",
            "step: 1001\n",
            "step: 1002\n",
            "step: 1003\n",
            "step: 1004\n",
            "step: 1005\n",
            "step: 1006\n",
            "step: 1007\n",
            "step: 1008\n",
            "step: 1009\n",
            "step: 1010\n",
            "step: 1011\n",
            "step: 1012\n",
            "step: 1013\n",
            "step: 1014\n",
            "step: 1015\n",
            "step: 1016\n",
            "step: 1017\n",
            "step: 1018\n",
            "step: 1019\n",
            "step: 1020\n",
            "step: 1021\n",
            "step: 1022\n",
            "step: 1023\n",
            "step: 1024\n",
            "step: 1025\n",
            "step: 1026\n",
            "step: 1027\n",
            "step: 1028\n",
            "step: 1029\n",
            "step: 1030\n",
            "step: 1031\n",
            "step: 1032\n",
            "step: 1033\n",
            "step: 1034\n",
            "step: 1035\n",
            "step: 1036\n",
            "step: 1037\n",
            "step: 1038\n",
            "step: 1039\n",
            "step: 1040\n",
            "step: 1041\n",
            "step: 1042\n",
            "step: 1043\n",
            "step: 1044\n",
            "step: 1045\n",
            "step: 1046\n",
            "step: 1047\n",
            "step: 1048\n",
            "step: 1049\n",
            "step: 1050\n",
            "step: 1051\n",
            "step: 1052\n",
            "step: 1053\n",
            "step: 1054\n",
            "step: 1055\n",
            "step: 1056\n",
            "step: 1057\n",
            "step: 1058\n",
            "step: 1059\n",
            "step: 1060\n",
            "step: 1061\n",
            "step: 1062\n",
            "step: 1063\n",
            "step: 1064\n",
            "step: 1065\n",
            "step: 1066\n",
            "step: 1067\n",
            "step: 1068\n",
            "step: 1069\n",
            "step: 1070\n",
            "step: 1071\n",
            "step: 1072\n",
            "step: 1073\n",
            "step: 1074\n",
            "step: 1075\n",
            "step: 1076\n",
            "step: 1077\n",
            "step: 1078\n",
            "step: 1079\n",
            "step: 1080\n",
            "step: 1081\n",
            "step: 1082\n",
            "step: 1083\n",
            "step: 1084\n",
            "step: 1085\n",
            "step: 1086\n",
            "step: 1087\n",
            "step: 1088\n",
            "step: 1089\n",
            "step: 1090\n",
            "step: 1091\n",
            "step: 1092\n",
            "step: 1093\n",
            "step: 1094\n",
            "step: 1095\n",
            "step: 1096\n",
            "step: 1097\n",
            "step: 1098\n",
            "step: 1099\n",
            "step: 1100\n",
            "step: 1101\n",
            "step: 1102\n",
            "step: 1103\n",
            "step: 1104\n",
            "step: 1105\n",
            "step: 1106\n",
            "step: 1107\n",
            "step: 1108\n",
            "step: 1109\n",
            "step: 1110\n",
            "step: 1111\n",
            "step: 1112\n",
            "step: 1113\n",
            "step: 1114\n",
            "step: 1115\n",
            "step: 1116\n",
            "step: 1117\n",
            "step: 1118\n",
            "step: 1119\n",
            "step: 1120\n",
            "step: 1121\n",
            "step: 1122\n",
            "step: 1123\n",
            "step: 1124\n",
            "step: 1125\n",
            "step: 1126\n",
            "step: 1127\n",
            "step: 1128\n",
            "step: 1129\n",
            "step: 1130\n",
            "step: 1131\n",
            "step: 1132\n",
            "step: 1133\n",
            "step: 1134\n",
            "step: 1135\n",
            "step: 1136\n",
            "step: 1137\n",
            "step: 1138\n",
            "step: 1139\n",
            "step: 1140\n",
            "step: 1141\n",
            "step: 1142\n",
            "step: 1143\n",
            "step: 1144\n",
            "step: 1145\n",
            "step: 1146\n",
            "step: 1147\n",
            "step: 1148\n",
            "step: 1149\n",
            "step: 1150\n",
            "step: 1151\n",
            "step: 1152\n",
            "step: 1153\n",
            "step: 1154\n",
            "step: 1155\n",
            "step: 1156\n",
            "step: 1157\n",
            "step: 1158\n",
            "step: 1159\n",
            "step: 1160\n",
            "step: 1161\n",
            "step: 1162\n",
            "step: 1163\n",
            "step: 1164\n",
            "step: 1165\n",
            "step: 1166\n",
            "step: 1167\n",
            "step: 1168\n",
            "step: 1169\n",
            "step: 1170\n",
            "step: 1171\n",
            "step: 1172\n",
            "step: 1173\n",
            "step: 1174\n",
            "step: 1175\n",
            "step: 1176\n",
            "step: 1177\n",
            "step: 1178\n",
            "step: 1179\n",
            "step: 1180\n",
            "step: 1181\n",
            "step: 1182\n",
            "step: 1183\n",
            "step: 1184\n",
            "step: 1185\n",
            "step: 1186\n",
            "step: 1187\n",
            "step: 1188\n",
            "step: 1189\n",
            "step: 1190\n",
            "step: 1191\n",
            "step: 1192\n",
            "step: 1193\n",
            "step: 1194\n",
            "step: 1195\n",
            "step: 1196\n",
            "step: 1197\n",
            "step: 1198\n",
            "step: 1199\n",
            "step: 1200\n",
            "step: 1201\n",
            "step: 1202\n",
            "step: 1203\n",
            "step: 1204\n",
            "step: 1205\n",
            "step: 1206\n",
            "step: 1207\n",
            "step: 1208\n",
            "step: 1209\n",
            "step: 1210\n",
            "step: 1211\n",
            "step: 1212\n",
            "step: 1213\n",
            "step: 1214\n",
            "step: 1215\n",
            "step: 1216\n",
            "step: 1217\n",
            "step: 1218\n",
            "step: 1219\n",
            "step: 1220\n",
            "step: 1221\n",
            "step: 1222\n",
            "step: 1223\n",
            "step: 1224\n",
            "step: 1225\n",
            "step: 1226\n",
            "step: 1227\n",
            "step: 1228\n",
            "step: 1229\n",
            "step: 1230\n",
            "step: 1231\n",
            "step: 1232\n",
            "step: 1233\n",
            "step: 1234\n",
            "step: 1235\n",
            "step: 1236\n",
            "step: 1237\n",
            "step: 1238\n",
            "step: 1239\n",
            "step: 1240\n",
            "step: 1241\n",
            "step: 1242\n",
            "step: 1243\n",
            "step: 1244\n",
            "step: 1245\n",
            "step: 1246\n",
            "step: 1247\n",
            "step: 1248\n",
            "step: 1249\n",
            "step: 1250\n",
            "step: 1251\n",
            "step: 1252\n",
            "step: 1253\n",
            "step: 1254\n",
            "step: 1255\n",
            "step: 1256\n",
            "step: 1257\n",
            "step: 1258\n",
            "step: 1259\n",
            "step: 1260\n",
            "step: 1261\n",
            "step: 1262\n",
            "step: 1263\n",
            "step: 1264\n",
            "step: 1265\n",
            "step: 1266\n",
            "step: 1267\n",
            "step: 1268\n",
            "step: 1269\n",
            "step: 1270\n",
            "step: 1271\n",
            "step: 1272\n",
            "step: 1273\n",
            "step: 1274\n",
            "step: 1275\n",
            "step: 1276\n",
            "step: 1277\n",
            "step: 1278\n",
            "step: 1279\n",
            "step: 1280\n",
            "step: 1281\n",
            "step: 1282\n",
            "step: 1283\n",
            "step: 1284\n",
            "step: 1285\n",
            "step: 1286\n",
            "step: 1287\n",
            "step: 1288\n",
            "step: 1289\n",
            "step: 1290\n",
            "step: 1291\n",
            "step: 1292\n",
            "step: 1293\n",
            "step: 1294\n",
            "step: 1295\n",
            "step: 1296\n",
            "step: 1297\n",
            "step: 1298\n",
            "step: 1299\n",
            "step: 1300\n",
            "step: 1301\n",
            "step: 1302\n",
            "step: 1303\n",
            "step: 1304\n",
            "step: 1305\n",
            "step: 1306\n",
            "step: 1307\n",
            "step: 1308\n",
            "step: 1309\n",
            "step: 1310\n",
            "step: 1311\n",
            "step: 1312\n",
            "step: 1313\n",
            "step: 1314\n",
            "step: 1315\n",
            "step: 1316\n",
            "step: 1317\n",
            "step: 1318\n",
            "step: 1319\n",
            "step: 1320\n",
            "step: 1321\n",
            "step: 1322\n",
            "step: 1323\n",
            "step: 1324\n",
            "step: 1325\n",
            "step: 1326\n",
            "step: 1327\n",
            "step: 1328\n",
            "step: 1329\n",
            "step: 1330\n",
            "step: 1331\n",
            "step: 1332\n",
            "step: 1333\n",
            "step: 1334\n",
            "step: 1335\n",
            "step: 1336\n",
            "step: 1337\n",
            "step: 1338\n",
            "step: 1339\n",
            "step: 1340\n",
            "step: 1341\n",
            "step: 1342\n",
            "step: 1343\n",
            "step: 1344\n",
            "step: 1345\n",
            "step: 1346\n",
            "step: 1347\n",
            "step: 1348\n",
            "step: 1349\n",
            "step: 1350\n",
            "step: 1351\n",
            "step: 1352\n",
            "step: 1353\n",
            "step: 1354\n",
            "step: 1355\n",
            "step: 1356\n",
            "step: 1357\n",
            "step: 1358\n",
            "step: 1359\n",
            "step: 1360\n",
            "step: 1361\n",
            "step: 1362\n",
            "step: 1363\n",
            "step: 1364\n",
            "step: 1365\n",
            "step: 1366\n",
            "step: 1367\n",
            "step: 1368\n",
            "step: 1369\n",
            "step: 1370\n",
            "step: 1371\n",
            "step: 1372\n",
            "step: 1373\n",
            "step: 1374\n",
            "step: 1375\n",
            "step: 1376\n",
            "step: 1377\n",
            "step: 1378\n",
            "step: 1379\n",
            "step: 1380\n",
            "step: 1381\n",
            "step: 1382\n",
            "step: 1383\n",
            "step: 1384\n",
            "step: 1385\n",
            "step: 1386\n",
            "step: 1387\n",
            "step: 1388\n",
            "step: 1389\n",
            "step: 1390\n",
            "step: 1391\n",
            "step: 1392\n",
            "step: 1393\n",
            "step: 1394\n",
            "step: 1395\n",
            "step: 1396\n",
            "step: 1397\n",
            "step: 1398\n",
            "step: 1399\n",
            "step: 1400\n",
            "step: 1401\n",
            "step: 1402\n",
            "step: 1403\n",
            "step: 1404\n",
            "step: 1405\n",
            "step: 1406\n",
            "step: 1407\n",
            "step: 1408\n",
            "step: 1409\n",
            "step: 1410\n",
            "step: 1411\n",
            "step: 1412\n",
            "step: 1413\n",
            "step: 1414\n",
            "step: 1415\n",
            "step: 1416\n",
            "step: 1417\n",
            "step: 1418\n",
            "step: 1419\n",
            "step: 1420\n",
            "step: 1421\n",
            "step: 1422\n",
            "step: 1423\n",
            "step: 1424\n",
            "step: 1425\n",
            "step: 1426\n",
            "step: 1427\n",
            "step: 1428\n",
            "step: 1429\n",
            "step: 1430\n",
            "step: 1431\n",
            "step: 1432\n",
            "step: 1433\n",
            "step: 1434\n",
            "step: 1435\n",
            "step: 1436\n",
            "step: 1437\n",
            "step: 1438\n",
            "step: 1439\n",
            "step: 1440\n",
            "step: 1441\n",
            "step: 1442\n",
            "step: 1443\n",
            "step: 1444\n",
            "step: 1445\n",
            "step: 1446\n",
            "step: 1447\n",
            "step: 1448\n",
            "step: 1449\n",
            "step: 1450\n",
            "step: 1451\n",
            "step: 1452\n",
            "step: 1453\n",
            "step: 1454\n",
            "step: 1455\n",
            "step: 1456\n",
            "step: 1457\n",
            "step: 1458\n",
            "step: 1459\n",
            "step: 1460\n",
            "step: 1461\n",
            "step: 1462\n",
            "step: 1463\n",
            "step: 1464\n",
            "step: 1465\n",
            "step: 1466\n",
            "step: 1467\n",
            "step: 1468\n",
            "step: 1469\n",
            "step: 1470\n",
            "step: 1471\n",
            "step: 1472\n",
            "step: 1473\n",
            "step: 1474\n",
            "step: 1475\n",
            "step: 1476\n",
            "step: 1477\n",
            "step: 1478\n",
            "step: 1479\n",
            "step: 1480\n",
            "step: 1481\n",
            "step: 1482\n",
            "step: 1483\n",
            "step: 1484\n",
            "step: 1485\n",
            "step: 1486\n",
            "step: 1487\n",
            "step: 1488\n",
            "step: 1489\n",
            "step: 1490\n",
            "step: 1491\n",
            "step: 1492\n",
            "step: 1493\n",
            "step: 1494\n",
            "step: 1495\n",
            "step: 1496\n",
            "step: 1497\n",
            "step: 1498\n",
            "step: 1499\n",
            "step: 1500\n",
            "step: 1501\n",
            "step: 1502\n",
            "step: 1503\n",
            "step: 1504\n",
            "step: 1505\n",
            "step: 1506\n",
            "step: 1507\n",
            "step: 1508\n",
            "step: 1509\n",
            "step: 1510\n",
            "step: 1511\n",
            "step: 1512\n",
            "step: 1513\n",
            "step: 1514\n",
            "step: 1515\n",
            "step: 1516\n",
            "step: 1517\n",
            "step: 1518\n",
            "step: 1519\n",
            "step: 1520\n",
            "step: 1521\n",
            "step: 1522\n",
            "step: 1523\n",
            "step: 1524\n",
            "step: 1525\n",
            "step: 1526\n",
            "step: 1527\n",
            "step: 1528\n",
            "step: 1529\n",
            "step: 1530\n",
            "step: 1531\n",
            "step: 1532\n",
            "step: 1533\n",
            "step: 1534\n",
            "step: 1535\n",
            "step: 1536\n",
            "step: 1537\n",
            "step: 1538\n",
            "step: 1539\n",
            "step: 1540\n",
            "step: 1541\n",
            "step: 1542\n",
            "step: 1543\n",
            "step: 1544\n",
            "step: 1545\n",
            "step: 1546\n",
            "step: 1547\n",
            "step: 1548\n",
            "step: 1549\n",
            "step: 1550\n",
            "step: 1551\n",
            "step: 1552\n",
            "step: 1553\n",
            "step: 1554\n",
            "step: 1555\n",
            "step: 1556\n",
            "step: 1557\n",
            "step: 1558\n",
            "step: 1559\n",
            "step: 1560\n",
            "step: 1561\n",
            "step: 1562\n",
            "step: 1563\n",
            "step: 1564\n",
            "step: 1565\n",
            "step: 1566\n",
            "step: 1567\n",
            "step: 1568\n",
            "step: 1569\n",
            "step: 1570\n",
            "step: 1571\n",
            "step: 1572\n",
            "step: 1573\n",
            "step: 1574\n",
            "step: 1575\n",
            "step: 1576\n",
            "step: 1577\n",
            "step: 1578\n",
            "step: 1579\n",
            "step: 1580\n",
            "step: 1581\n",
            "step: 1582\n",
            "step: 1583\n",
            "step: 1584\n",
            "step: 1585\n",
            "step: 1586\n",
            "step: 1587\n",
            "step: 1588\n",
            "step: 1589\n",
            "step: 1590\n",
            "step: 1591\n",
            "step: 1592\n",
            "step: 1593\n",
            "step: 1594\n",
            "step: 1595\n",
            "step: 1596\n",
            "step: 1597\n",
            "step: 1598\n",
            "step: 1599\n",
            "step: 1600\n",
            "step: 1601\n",
            "step: 1602\n",
            "step: 1603\n",
            "step: 1604\n",
            "step: 1605\n",
            "step: 1606\n",
            "step: 1607\n",
            "step: 1608\n",
            "step: 1609\n",
            "step: 1610\n",
            "step: 1611\n",
            "step: 1612\n",
            "step: 1613\n",
            "step: 1614\n",
            "step: 1615\n",
            "step: 1616\n",
            "step: 1617\n",
            "step: 1618\n",
            "step: 1619\n",
            "step: 1620\n",
            "step: 1621\n",
            "step: 1622\n",
            "step: 1623\n",
            "step: 1624\n",
            "step: 1625\n",
            "step: 1626\n",
            "step: 1627\n",
            "step: 1628\n",
            "step: 1629\n",
            "step: 1630\n",
            "step: 1631\n",
            "step: 1632\n",
            "step: 1633\n",
            "step: 1634\n",
            "step: 1635\n",
            "step: 1636\n",
            "step: 1637\n",
            "step: 1638\n",
            "step: 1639\n",
            "step: 1640\n",
            "step: 1641\n",
            "step: 1642\n",
            "step: 1643\n",
            "step: 1644\n",
            "step: 1645\n",
            "step: 1646\n",
            "step: 1647\n",
            "step: 1648\n",
            "step: 1649\n",
            "step: 1650\n",
            "step: 1651\n",
            "step: 1652\n",
            "step: 1653\n",
            "step: 1654\n",
            "step: 1655\n",
            "step: 1656\n",
            "step: 1657\n",
            "step: 1658\n",
            "step: 1659\n",
            "step: 1660\n",
            "step: 1661\n",
            "step: 1662\n",
            "step: 1663\n",
            "step: 1664\n",
            "step: 1665\n",
            "step: 1666\n",
            "step: 1667\n",
            "step: 1668\n",
            "step: 1669\n",
            "step: 1670\n",
            "step: 1671\n",
            "step: 1672\n",
            "step: 1673\n",
            "step: 1674\n",
            "step: 1675\n",
            "step: 1676\n",
            "step: 1677\n",
            "step: 1678\n",
            "step: 1679\n",
            "step: 1680\n",
            "step: 1681\n",
            "step: 1682\n",
            "step: 1683\n",
            "step: 1684\n",
            "step: 1685\n",
            "step: 1686\n",
            "step: 1687\n",
            "step: 1688\n",
            "step: 1689\n",
            "step: 1690\n",
            "step: 1691\n",
            "step: 1692\n",
            "step: 1693\n",
            "step: 1694\n",
            "step: 1695\n",
            "step: 1696\n",
            "step: 1697\n",
            "step: 1698\n",
            "step: 1699\n",
            "step: 1700\n",
            "step: 1701\n",
            "step: 1702\n",
            "step: 1703\n",
            "step: 1704\n",
            "step: 1705\n",
            "step: 1706\n",
            "step: 1707\n",
            "step: 1708\n",
            "step: 1709\n",
            "step: 1710\n",
            "step: 1711\n",
            "step: 1712\n",
            "step: 1713\n",
            "step: 1714\n",
            "step: 1715\n",
            "step: 1716\n",
            "step: 1717\n",
            "step: 1718\n",
            "step: 1719\n",
            "step: 1720\n",
            "step: 1721\n",
            "step: 1722\n",
            "step: 1723\n",
            "step: 1724\n",
            "step: 1725\n",
            "step: 1726\n",
            "step: 1727\n",
            "step: 1728\n",
            "step: 1729\n",
            "step: 1730\n",
            "step: 1731\n",
            "step: 1732\n",
            "step: 1733\n",
            "step: 1734\n",
            "step: 1735\n",
            "step: 1736\n",
            "step: 1737\n",
            "step: 1738\n",
            "step: 1739\n",
            "step: 1740\n",
            "step: 1741\n",
            "step: 1742\n",
            "step: 1743\n",
            "step: 1744\n",
            "step: 1745\n",
            "step: 1746\n",
            "step: 1747\n",
            "step: 1748\n",
            "step: 1749\n",
            "step: 1750\n",
            "step: 1751\n",
            "step: 1752\n",
            "step: 1753\n",
            "step: 1754\n",
            "step: 1755\n",
            "step: 1756\n",
            "step: 1757\n",
            "step: 1758\n",
            "step: 1759\n",
            "step: 1760\n",
            "step: 1761\n",
            "step: 1762\n",
            "step: 1763\n",
            "step: 1764\n",
            "step: 1765\n",
            "step: 1766\n",
            "step: 1767\n",
            "step: 1768\n",
            "step: 1769\n",
            "step: 1770\n",
            "step: 1771\n",
            "step: 1772\n",
            "step: 1773\n",
            "step: 1774\n",
            "step: 1775\n",
            "step: 1776\n",
            "step: 1777\n",
            "step: 1778\n",
            "step: 1779\n",
            "step: 1780\n",
            "step: 1781\n",
            "step: 1782\n",
            "step: 1783\n",
            "step: 1784\n",
            "step: 1785\n",
            "step: 1786\n",
            "step: 1787\n",
            "step: 1788\n",
            "step: 1789\n",
            "step: 1790\n",
            "step: 1791\n",
            "step: 1792\n",
            "step: 1793\n",
            "step: 1794\n",
            "step: 1795\n",
            "step: 1796\n",
            "step: 1797\n",
            "step: 1798\n",
            "step: 1799\n",
            "step: 1800\n",
            "step: 1801\n",
            "step: 1802\n",
            "step: 1803\n",
            "step: 1804\n",
            "step: 1805\n",
            "step: 1806\n",
            "step: 1807\n",
            "step: 1808\n",
            "step: 1809\n",
            "step: 1810\n",
            "step: 1811\n",
            "step: 1812\n",
            "step: 1813\n",
            "step: 1814\n",
            "step: 1815\n",
            "step: 1816\n",
            "step: 1817\n",
            "step: 1818\n",
            "step: 1819\n",
            "step: 1820\n",
            "step: 1821\n",
            "step: 1822\n",
            "step: 1823\n",
            "step: 1824\n",
            "step: 1825\n",
            "step: 1826\n",
            "step: 1827\n",
            "step: 1828\n",
            "step: 1829\n",
            "step: 1830\n",
            "step: 1831\n",
            "step: 1832\n",
            "step: 1833\n",
            "step: 1834\n",
            "step: 1835\n",
            "step: 1836\n",
            "step: 1837\n",
            "step: 1838\n",
            "step: 1839\n",
            "step: 1840\n",
            "step: 1841\n",
            "step: 1842\n",
            "step: 1843\n",
            "step: 1844\n",
            "step: 1845\n",
            "step: 1846\n",
            "step: 1847\n",
            "step: 1848\n",
            "step: 1849\n",
            "step: 1850\n",
            "step: 1851\n",
            "step: 1852\n",
            "step: 1853\n",
            "step: 1854\n",
            "step: 1855\n",
            "step: 1856\n",
            "step: 1857\n",
            "step: 1858\n",
            "step: 1859\n",
            "step: 1860\n",
            "step: 1861\n",
            "step: 1862\n",
            "step: 1863\n",
            "step: 1864\n",
            "step: 1865\n",
            "step: 1866\n",
            "step: 1867\n",
            "step: 1868\n",
            "step: 1869\n",
            "step: 1870\n",
            "step: 1871\n",
            "step: 1872\n",
            "step: 1873\n",
            "step: 1874\n",
            "step: 1875\n",
            "step: 1876\n",
            "step: 1877\n",
            "step: 1878\n",
            "step: 1879\n",
            "step: 1880\n",
            "step: 1881\n",
            "step: 1882\n",
            "step: 1883\n",
            "step: 1884\n",
            "step: 1885\n",
            "step: 1886\n",
            "step: 1887\n",
            "step: 1888\n",
            "step: 1889\n",
            "step: 1890\n",
            "step: 1891\n",
            "step: 1892\n",
            "step: 1893\n",
            "step: 1894\n",
            "step: 1895\n",
            "step: 1896\n",
            "step: 1897\n",
            "step: 1898\n",
            "step: 1899\n",
            "step: 1900\n",
            "step: 1901\n",
            "step: 1902\n",
            "step: 1903\n",
            "step: 1904\n",
            "step: 1905\n",
            "step: 1906\n",
            "step: 1907\n",
            "step: 1908\n",
            "step: 1909\n",
            "step: 1910\n",
            "step: 1911\n",
            "step: 1912\n",
            "step: 1913\n",
            "step: 1914\n",
            "step: 1915\n",
            "step: 1916\n",
            "step: 1917\n",
            "step: 1918\n",
            "step: 1919\n",
            "step: 1920\n",
            "step: 1921\n",
            "step: 1922\n",
            "step: 1923\n",
            "step: 1924\n",
            "step: 1925\n",
            "step: 1926\n",
            "step: 1927\n",
            "step: 1928\n",
            "step: 1929\n",
            "step: 1930\n",
            "step: 1931\n",
            "step: 1932\n",
            "step: 1933\n",
            "step: 1934\n",
            "step: 1935\n",
            "step: 1936\n",
            "step: 1937\n",
            "step: 1938\n",
            "step: 1939\n",
            "step: 1940\n",
            "step: 1941\n",
            "step: 1942\n",
            "step: 1943\n",
            "step: 1944\n",
            "step: 1945\n",
            "step: 1946\n",
            "step: 1947\n",
            "step: 1948\n",
            "step: 1949\n",
            "step: 1950\n",
            "step: 1951\n",
            "step: 1952\n",
            "step: 1953\n",
            "step: 1954\n",
            "step: 1955\n",
            "step: 1956\n",
            "step: 1957\n",
            "step: 1958\n",
            "step: 1959\n",
            "step: 1960\n",
            "step: 1961\n",
            "step: 1962\n",
            "step: 1963\n",
            "step: 1964\n",
            "step: 1965\n",
            "step: 1966\n",
            "step: 1967\n",
            "step: 1968\n",
            "step: 1969\n",
            "step: 1970\n",
            "step: 1971\n",
            "step: 1972\n",
            "step: 1973\n",
            "step: 1974\n",
            "step: 1975\n",
            "step: 1976\n",
            "step: 1977\n",
            "step: 1978\n",
            "step: 1979\n",
            "step: 1980\n",
            "step: 1981\n",
            "step: 1982\n",
            "step: 1983\n",
            "step: 1984\n",
            "step: 1985\n",
            "step: 1986\n",
            "step: 1987\n",
            "step: 1988\n",
            "step: 1989\n",
            "step: 1990\n",
            "step: 1991\n",
            "step: 1992\n",
            "step: 1993\n",
            "step: 1994\n",
            "step: 1995\n",
            "step: 1996\n",
            "step: 1997\n",
            "step: 1998\n",
            "step: 1999\n",
            "step: 2000\n",
            "step: 2001\n",
            "step: 2002\n",
            "step: 2003\n",
            "step: 2004\n",
            "step: 2005\n",
            "step: 2006\n",
            "step: 2007\n",
            "step: 2008\n",
            "step: 2009\n",
            "step: 2010\n",
            "step: 2011\n",
            "step: 2012\n",
            "step: 2013\n",
            "step: 2014\n",
            "step: 2015\n",
            "step: 2016\n",
            "step: 2017\n",
            "step: 2018\n",
            "step: 2019\n",
            "step: 2020\n",
            "step: 2021\n",
            "step: 2022\n",
            "step: 2023\n",
            "step: 2024\n",
            "step: 2025\n",
            "step: 2026\n",
            "step: 2027\n",
            "step: 2028\n",
            "step: 2029\n",
            "step: 2030\n",
            "step: 2031\n",
            "step: 2032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mv '/content/results/results' '/content/drive/MyDrive'"
      ],
      "metadata": {
        "id": "Jz4MwhYL4DZS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}